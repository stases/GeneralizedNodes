{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from networks import FractalNet, FractalNetShared, Net, GNN_no_rel, GNN\n",
    "from subgraph import Graph_to_Subgraph\n",
    "from train import train_model, get_qm9\n",
    "from train import train_model, get_qm9\n",
    "from subgraph import Subgraph\n",
    "from layers import MP, SimpleMP\n",
    "from utils import catch_lone_sender\n",
    "from torch_geometric.utils import remove_isolated_nodes\n",
    "from torch_geometric.nn import GCNConv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/Documents/GitHub/FractalMessagePassing/train.py:23: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = get_qm9('./data')\n",
    "# get a sample data\n",
    "data = dataset[0]\n",
    "sample_data = data[0].to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "# find the smallest data and set it as sample_data\n",
    "for data_point in data:\n",
    "    if data_point.num_nodes < sample_data.num_nodes:\n",
    "        # stop if the number of num nodes is less than 5\n",
    "        if data_point.num_nodes < 6:\n",
    "            break\n",
    "        sample_data = data_point.to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[8, 11], edge_index=[2, 16], edge_attr=[16, 4], y=[1, 19], pos=[8, 3], idx=[1], name='gdb_144', z=[8])"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "subgraph_example = Subgraph(sample_data, mode='fractal').convert_to_subgraph()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  torch.Size([72, 5])\n",
      "Number of edges:  torch.Size([2, 16])\n",
      "Subedge index torch.Size([2, 128])\n",
      "Maximum value in subedge index:  tensor(71)\n"
     ]
    }
   ],
   "source": [
    "# print all the statistics\n",
    "print('Number of nodes: ', subgraph_example.x.shape)\n",
    "print('Number of edges: ', subgraph_example.edge_index.shape)\n",
    "print('Subedge index', subgraph_example.subgraph_edge_index.shape)\n",
    "# print the maximum value in the subedge index\n",
    "print('Maximum value in subedge index: ', torch.max(subgraph_example.subgraph_edge_index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "       # edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "# Initialize a one MP layer\n",
    "node_features = 5\n",
    "hidden_features = 2\n",
    "edge_features = 0\n",
    "\n",
    "x = subgraph_example.x.clone()\n",
    "edge_index = subgraph_example.edge_index\n",
    "subgraph_edge_index = subgraph_example.subgraph_edge_index\n",
    "node_subnode_index = subgraph_example.node_subnode_index\n",
    "subnode_node_index = subgraph_example.subnode_node_index\n",
    "ground_node = subgraph_example.ground_node\n",
    "\n",
    "MP_layer = MP(hidden_features, edge_features, hidden_features, hidden_features)\n",
    "GCN_layer = GCNConv(hidden_features, hidden_features)\n",
    "embedding = nn.Linear(node_features, hidden_features)\n",
    "\n",
    "x = embedding(x)\n",
    "num_nodes = x.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "x_original = x.clone()\n",
    "#print('x_original', x_original)\n",
    "update_mask = catch_lone_sender(edge_index, num_nodes)\n",
    "x_backup = x[~update_mask]\n",
    "x = MP_layer(x, edge_index) +3\n",
    "x[~update_mask] = x_backup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.5152,  2.4932],\n        [ 2.6387,  2.7755],\n        [ 2.6122,  2.8730],\n        [ 2.6146,  2.8703],\n        [ 2.5930,  2.6250],\n        [ 2.5305,  2.5506],\n        [ 2.5305,  2.5506],\n        [ 2.5305,  2.5506],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5239, -0.7072],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.4755, -0.0507],\n        [ 0.7347, -0.3035],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718],\n        [ 0.5418, -0.4718]], grad_fn=<IndexPutBackward0>)"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "update_mask = catch_lone_sender(node_subnode_index, num_nodes)\n",
    "x_backup = x[~update_mask]\n",
    "x = MP_layer(x, node_subnode_index)\n",
    "x[~update_mask] = x_backup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.5152,  2.4932],\n        [ 2.6387,  2.7755],\n        [ 2.6122,  2.8730],\n        [ 2.6146,  2.8703],\n        [ 2.5930,  2.6250],\n        [ 2.5305,  2.5506],\n        [ 2.5305,  2.5506],\n        [ 2.5305,  2.5506],\n        [-0.3770, -0.3682],\n        [-0.3386, -0.1820],\n        [-0.3386, -0.1820],\n        [-0.3386, -0.1820],\n        [-0.3774, -0.3369],\n        [-0.3618, -0.3108],\n        [-0.3618, -0.3108],\n        [-0.3618, -0.3108],\n        [-0.3681, -0.3568],\n        [-0.3424, -0.1777],\n        [-0.3424, -0.1777],\n        [-0.3424, -0.1777],\n        [-0.3685, -0.3254],\n        [-0.3529, -0.2993],\n        [-0.3529, -0.2993],\n        [-0.3529, -0.2993],\n        [-0.3671, -0.3555],\n        [-0.3429, -0.1772],\n        [-0.3429, -0.1772],\n        [-0.3429, -0.1772],\n        [-0.3675, -0.3241],\n        [-0.3518, -0.2980],\n        [-0.3518, -0.2980],\n        [-0.3518, -0.2980],\n        [-0.3671, -0.3554],\n        [-0.3429, -0.1772],\n        [-0.3429, -0.1772],\n        [-0.3429, -0.1772],\n        [-0.3674, -0.3241],\n        [-0.3518, -0.2980],\n        [-0.3518, -0.2980],\n        [-0.3518, -0.2980],\n        [-0.3723, -0.3621],\n        [-0.3406, -0.1797],\n        [-0.3406, -0.1797],\n        [-0.3406, -0.1797],\n        [-0.3726, -0.3308],\n        [-0.3570, -0.3047],\n        [-0.3570, -0.3047],\n        [-0.3570, -0.3047],\n        [-0.3755, -0.3663],\n        [-0.3393, -0.1812],\n        [-0.3393, -0.1812],\n        [-0.3393, -0.1812],\n        [-0.3759, -0.3349],\n        [-0.3602, -0.3088],\n        [-0.3602, -0.3088],\n        [-0.3602, -0.3088],\n        [-0.3755, -0.3663],\n        [-0.3393, -0.1812],\n        [-0.3393, -0.1812],\n        [-0.3393, -0.1812],\n        [-0.3759, -0.3349],\n        [-0.3602, -0.3088],\n        [-0.3602, -0.3088],\n        [-0.3602, -0.3088],\n        [-0.3755, -0.3663],\n        [-0.3393, -0.1812],\n        [-0.3393, -0.1812],\n        [-0.3393, -0.1812],\n        [-0.3759, -0.3349],\n        [-0.3602, -0.3088],\n        [-0.3602, -0.3088],\n        [-0.3602, -0.3088]], grad_fn=<IndexPutBackward0>)"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 1.]])"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph_example.x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [1.3722, 0.6890],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [1.3725, 0.6894],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [1.3725, 0.6894],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [1.3725, 0.6894],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [1.3725, 0.6894],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480],\n        [0.3251, 0.1480]], grad_fn=<ScatterAddBackward0>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = MP_layer(x, subgraph_edge_index)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.6612, 0.7883],\n        [1.6612, 0.7883],\n        [1.6612, 0.7883],\n        [1.6612, 0.7883],\n        [1.6612, 0.7883],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000]], grad_fn=<ScatterAddBackward0>)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = MP_layer(x, subnode_node_index)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are they the same tensors:  True\n",
      "Node states:  tensor([[1.2365, 0.2394],\n",
      "        [1.2365, 0.2394],\n",
      "        [1.2365, 0.2394],\n",
      "        [0.6183, 0.1197],\n",
      "        [0.6183, 0.1197],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000]], grad_fn=<IndexPutBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass with edge_index\n",
    "x_subnode_original = x[~ground_node]\n",
    "filtered_edge_index, _, mask = remove_isolated_nodes(edge_index)\n",
    "x[ground_node] = MP_layer(x[ground_node], filtered_edge_index)\n",
    "# print both of them\n",
    "print('Are they the same tensors: ', torch.equal(x[~ground_node], x_subnode_original))\n",
    "print('Node states: ', x)\n",
    "# check if x[~ground_node] and x_subnode_original are the same pytorch tensors\n",
    "x_node_original = x[ground_node]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are they the same tensors:  False\n",
      "Node states:  tensor([[ 0.2830, -0.3501],\n",
      "        [ 0.2766, -0.3489],\n",
      "        [ 0.2734, -0.3482],\n",
      "        [ 0.2730, -0.3482],\n",
      "        [ 0.2730, -0.3482],\n",
      "        [ 0.2730, -0.3482],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2964, -0.3933],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2964, -0.3933],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2964, -0.3933],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2964, -0.3933],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2964, -0.3933],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2972, -0.3940],\n",
      "        [ 0.2964, -0.3933],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878],\n",
      "        [ 0.2902, -0.3878]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = MP_layer(x, node_subnode_index)\n",
    "# check if x[ground_node] and x_node_original are the same pytorch tensors\n",
    "print('Are they the same tensors: ', torch.equal(x, x_node_original))\n",
    "print('Node states: ', x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# forward pass with edge_index\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground node states:  tensor([[-0.0924, -1.3850],\n",
      "        [-0.0924, -1.3850],\n",
      "        [-0.2471, -1.0797],\n",
      "        [-0.2157, -1.1582],\n",
      "        [-0.2157, -1.1582],\n",
      "        [-0.2157, -1.1582]], grad_fn=<IndexBackward0>)\n",
      "Subnode node states:  tensor([[ 0.0076, -0.8455],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [-0.1285, -0.5832],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [-0.1285, -0.5832],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [-0.1285, -0.5832],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [-0.1285, -0.5832],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [-0.1285, -0.5832],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [ 0.0076, -0.8455],\n",
      "        [-0.1285, -0.5832],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103],\n",
      "        [-0.1175, -0.7103]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ground_node_states = MP_layer(x, subnode_node_index)[ground_node]\n",
    "subnode_node_states = MP_layer(x, subnode_node_index)[~ground_node]\n",
    "# print both of them\n",
    "print('Ground node states: ', ground_node_states)\n",
    "print('Subnode node states: ', subnode_node_states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}