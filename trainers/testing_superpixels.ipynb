{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:37:29.170311582Z",
     "start_time": "2023-06-26T14:37:26.082437725Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from geomloss import SamplesLoss\n",
    "from sklearn.cluster import KMeans\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url, extract_zip\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.transforms import RadiusGraph, Compose\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import wandb\n",
    "from utils.transforms import Graph_to_Subgraph\n",
    "import wandb\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch_geometric.data\n",
    "import torch\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def sinkhorn_loss(x, y):\n",
    "    # \"sinkhorn\" loss ('blur':Ïƒ=0.01, 'scaling':0.9)\n",
    "    loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01, scaling=0.9)\n",
    "    return loss(x, y)\n",
    "\n",
    "def get_datasets(data_dir, batch_size, radius, subgraph_dict=None):\n",
    "    cluster_k = 3\n",
    "    transforms = []\n",
    "    transforms.append(RadiusGraph(radius))\n",
    "    if subgraph_dict is not None:\n",
    "        subgraph_mode = subgraph_dict.get(\"mode\", None)\n",
    "        transforms.append(Graph_to_Subgraph(mode=subgraph_mode))\n",
    "    transforms = Compose(transforms)\n",
    "    # TODO: RESCALE THE DATASET BACK TO THE ORIGINAL SIZE\n",
    "    train_val_set = MNISTSuperpixels(root=data_dir, transform=transforms, train=True, cluster_k=cluster_k)\n",
    "    # split train into train and val sets by taking the last 10% of the training set\n",
    "    train_set = train_val_set[:int(len(train_val_set) * 0.9)]\n",
    "    train_set = train_set[:1]\n",
    "    val_set = train_val_set[int(len(train_val_set) * 0.9):]\n",
    "    val_set = val_set[:1]\n",
    "    test_set = MNISTSuperpixels(root=data_dir, transform=transforms, train=False, cluster_k=cluster_k)\n",
    "    # print which transforms are we using\n",
    "    print(\"Transforms: \", transforms)\n",
    "    #assert len(train_set) + len(val_set) == len(train_val_set)\n",
    "\n",
    "    train_loader = tg.loader.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = tg.loader.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = tg.loader.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor\n",
    "\n",
    "class KMeansClustering(BaseTransform):\n",
    "    def __init__(self, num_clusters):\n",
    "        self.num_clusters = num_clusters\n",
    "\n",
    "    def fit(self, data):\n",
    "        pos = data.pos\n",
    "        x = data.x\n",
    "\n",
    "        N = data.num_nodes\n",
    "        k = N // self.num_clusters\n",
    "\n",
    "        pos_flattened = pos.view(-1, pos.size(-1)).numpy()\n",
    "\n",
    "        kmeans = KMeans(n_clusters=k, n_init=3)\n",
    "        self.labels = kmeans.fit_predict(pos_flattened)\n",
    "        self.labels = torch.from_numpy(self.labels)  # Convert labels to torch.Tensor\n",
    "        self.centroids_pos = torch.zeros(k, pos.size(-1))\n",
    "        self.centroids_x = torch.zeros(k, x.size(-1))\n",
    "\n",
    "        for node_idx, cluster_idx in enumerate(self.labels):\n",
    "            self.centroids_pos[cluster_idx] += pos[node_idx]\n",
    "            self.centroids_x[cluster_idx] += x[node_idx]\n",
    "\n",
    "        for cluster_idx in range(k):\n",
    "            indices = torch.nonzero(self.labels == cluster_idx).view(-1)\n",
    "            count = indices.size(0)\n",
    "\n",
    "            self.centroids_pos[cluster_idx] /= count\n",
    "            self.centroids_x[cluster_idx] /= count\n",
    "\n",
    "    def __call__(self, data):\n",
    "        pos = data.pos\n",
    "        x = data.x\n",
    "\n",
    "        # Assign the precomputed centroids and labels\n",
    "        data.x = self.centroids_x\n",
    "        data.x_full = x\n",
    "        data.pos = self.centroids_pos\n",
    "        data.pos_full = pos\n",
    "        data.cluster_labels = self.labels\n",
    "\n",
    "        return data\n",
    "\n",
    "class MNISTSuperpixels(InMemoryDataset):\n",
    "    url = 'https://data.pyg.org/datasets/MNISTSuperpixels.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        cluster_k: int = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.cluster_k = cluster_k  # Store cluster_k for later use\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        path = self.processed_paths[0] if train else self.processed_paths[1]\n",
    "        self.data, self.slices = torch.load(path)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return 'MNISTSuperpixels.pt'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> List[str]:\n",
    "        if self.cluster_k is None:\n",
    "            return ['train_data.pt', 'test_data.pt']\n",
    "        else:\n",
    "            return [f'train_data_k{self.cluster_k}.pt', f'test_data_k{self.cluster_k}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.raw_dir)\n",
    "        extract_zip(path, self.raw_dir)\n",
    "        os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        inputs = torch.load(self.raw_paths[0])\n",
    "        for i in range(len(inputs)):\n",
    "            data_list = [Data(**data_dict) for data_dict in inputs[i]]\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "            if self.cluster_k is not None:\n",
    "                with tqdm(total=len(data_list), desc=f'Cluster K={self.cluster_k}') as pbar:\n",
    "                    for j in range(len(data_list)):\n",
    "                        cluster_transform = KMeansClustering(num_clusters=self.cluster_k)\n",
    "                        cluster_transform.fit(data_list[j])\n",
    "                        data_list[j] = cluster_transform(data_list[j])\n",
    "                        pbar.update(1)\n",
    "\n",
    "            torch.save(self.collate(data_list), self.processed_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class RFF(nn.Module):\n",
    "    def __init__(self, in_features, out_features, sigma=1.0):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        if out_features % 2 != 0:\n",
    "            self.compensation = 1\n",
    "        else:\n",
    "            self.compensation = 0\n",
    "\n",
    "        B = torch.randn(int(out_features / 2) + self.compensation, in_features) * sigma\n",
    "        B /= math.sqrt(2)\n",
    "        self.register_buffer(\"B\", B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.linear(x, self.B)\n",
    "        x = torch.cat((x.sin(), x.cos()), dim=-1)\n",
    "        if self.compensation:\n",
    "            x = x[..., :-1]\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"in_features={}, out_features={}, sigma={}\".format(\n",
    "            self.in_features, self.out_features, self.sigma\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:44:57.932456971Z",
     "start_time": "2023-06-26T14:44:57.889256357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "#from torch_scatter import scatter_add, scatter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.utils import softmax\n",
    "import math\n",
    "from typing import Optional, Tuple, Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_scatter import scatter\n",
    "import torch_geometric as tg\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.nn.conv import TransformerConv\n",
    "from utils.tools import catch_lone_sender, fully_connected_edge_index\n",
    "class EGNN_FullLayer(tg.nn.MessagePassing):\n",
    "    def __init__(self, emb_dim, activation=\"relu\", norm=\"layer\", aggr=\"add\", RFF_dim=64, RFF_sigma=5, **kwargs):\n",
    "        \"\"\"E(n) Equivariant GNN Layer\n",
    "\n",
    "        Paper: E(n) Equivariant Graph Neural Networks, Satorras et al.\n",
    "\n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "        self.update_pos = True\n",
    "        self.emb_dim = emb_dim\n",
    "        self.RFF_dim = RFF_dim\n",
    "        self.RFF_sigma = RFF_sigma\n",
    "        self.activation = {\"swish\": nn.SiLU(), \"relu\": nn.ReLU()}[activation]\n",
    "        self.norm = {\"layer\": torch.nn.LayerNorm, \"batch\": torch.nn.BatchNorm1d}[norm]\n",
    "\n",
    "        # MLP `\\psi_h` for computing messages `m_ij`\n",
    "        self.mlp_msg = nn.Sequential(\n",
    "             nn.Linear(2 * emb_dim + 1 if self.RFF_dim is None else 2 * emb_dim + RFF_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        # MLP `\\psi_x` for computing messages `\\overrightarrow{m}_ij`\n",
    "        self.mlp_pos = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim), self.norm(emb_dim), self.activation, nn.Linear(emb_dim, 1)\n",
    "        )\n",
    "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
    "        self.mlp_upd = nn.Sequential(\n",
    "            nn.Linear(2 * emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        if self.RFF_dim is not None:\n",
    "            self.RFF = RFF(1, RFF_dim, RFF_sigma)\n",
    "    def forward(self, h, pos, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            pos: (n, 3) - initial node coordinates\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "        Returns:\n",
    "            out: [(n, d),(n,3)] - updated node features\n",
    "        \"\"\"\n",
    "        out = self.propagate(edge_index, h=h, pos=pos)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, pos_i, pos_j):\n",
    "        # Compute messages\n",
    "        pos_diff = pos_i - pos_j\n",
    "        dists = torch.norm(pos_diff, dim=-1).unsqueeze(1)\n",
    "        if self.RFF_dim is not None:\n",
    "            #print(\"USING RFF\")\n",
    "            dists = self.RFF(dists)\n",
    "        msg = torch.cat([h_i, h_j, dists], dim=-1)\n",
    "        msg = self.mlp_msg(msg)\n",
    "        # Scale magnitude of displacement vector\n",
    "        pos_diff = pos_diff * self.mlp_pos(msg)  # torch.clamp(updates, min=-100, max=100)\n",
    "        return msg, pos_diff\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        msgs, pos_diffs = inputs\n",
    "\n",
    "        # Aggregate messages\n",
    "        msg_aggr = scatter(msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        # Aggregate displacement vectors\n",
    "        if self.update_pos:\n",
    "            pos_aggr = scatter(pos_diffs, index, dim=self.node_dim, reduce=\"mean\")\n",
    "\n",
    "        nodes_to_upd = torch.unique(index)\n",
    "        msg_aggr = msg_aggr[nodes_to_upd]\n",
    "\n",
    "        if self.update_pos:\n",
    "            pos_aggr = pos_aggr[nodes_to_upd]\n",
    "        else:\n",
    "            pos_aggr = None\n",
    "\n",
    "        return msg_aggr, pos_aggr, nodes_to_upd\n",
    "\n",
    "    def update(self, aggr_out, h, pos):\n",
    "        msg_aggr, pos_aggr, nodes_to_upd = aggr_out\n",
    "\n",
    "        upd_out = h\n",
    "        upd_out[nodes_to_upd] = self.mlp_upd(torch.cat([h[nodes_to_upd], msg_aggr], dim=-1))\n",
    "        if self.update_pos:\n",
    "            upd_pos = pos\n",
    "            #print('pos before is ', pos)\n",
    "            #print('pos aggr is ', pos_aggr)\n",
    "            upd_pos[nodes_to_upd] = pos[nodes_to_upd] + pos_aggr\n",
    "            # print the difference\n",
    "            #print('pos after is ', upd_pos)\n",
    "\n",
    "        else:\n",
    "            upd_pos = pos\n",
    "\n",
    "        return upd_out, upd_pos\n",
    "\n",
    "\n",
    "class Superpixel_EGNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            depth=5,\n",
    "            hidden_features=128,\n",
    "            node_features=1,\n",
    "            out_features=1,\n",
    "            activation=\"relu\",\n",
    "            norm=\"layer\",\n",
    "            aggr=\"sum\",\n",
    "            pool=\"add\",\n",
    "            residual=True,\n",
    "            mask=True,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Name of the network\n",
    "        self.name = \"Superpixel_EGNN\"\n",
    "        self.depth = depth\n",
    "        # Embedding lookup for initial node features\n",
    "        self.emb_in = nn.Linear(node_features, hidden_features)\n",
    "\n",
    "        # Stack of GNN layers\n",
    "        self.ground_mps = torch.nn.ModuleList()\n",
    "        self.ground_to_sub_mps = torch.nn.ModuleList()\n",
    "        self.sub_mps = torch.nn.ModuleList()\n",
    "        self.sub_to_ground_mps = torch.nn.ModuleList()\n",
    "        for layer in range(depth):\n",
    "            self.ground_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "            self.ground_to_sub_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "            self.sub_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "            #self.sub_to_ground_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "        self.residual = residual\n",
    "        self.mask = mask\n",
    "\n",
    "        self.pred = torch.nn.Sequential(\n",
    "        torch.nn.Linear(hidden_features*1, hidden_features),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "    def forward(self, batch):\n",
    "\n",
    "        h = self.emb_in(batch.x)  # (n,) -> (n, d)\n",
    "        pos = batch.pos.clone()  # (n, 3)\n",
    "        pos[~batch.ground_node] += torch.randn_like(pos[~batch.ground_node]) * 0.01\n",
    "        h_ground = h[batch.ground_node]\n",
    "        pos_ground = pos[batch.ground_node]\n",
    "\n",
    "        h_sub = h[~batch.ground_node]\n",
    "        pos_sub = pos[~batch.ground_node]\n",
    "\n",
    "        for layer_idx in range(self.depth):\n",
    "            h_old = h.clone()\n",
    "            h_0 = h\n",
    "            pos_old = pos.clone()\n",
    "            h_update, pos_update = self.ground_mps[layer_idx](h, pos, batch.edge_index)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "            pos = pos_update\n",
    "            if self.mask:\n",
    "                pos[batch.ground_node] = pos_old[batch.ground_node]\n",
    "\n",
    "            pos_old = pos.clone()\n",
    "            h_update, pos_update = self.ground_to_sub_mps[layer_idx](h, pos, batch.node_subnode_index)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "            pos = pos_update\n",
    "            if self.mask:\n",
    "                pos[batch.ground_node] = pos_old[batch.ground_node]\n",
    "            pos_old = pos.clone()\n",
    "\n",
    "            pos_before = pos.clone()\n",
    "            h_update, pos_update = self.sub_mps[layer_idx](h, pos, batch.subgraph_edge_index)\n",
    "            #print('pos update is', pos_update)\n",
    "            #print('difference is', pos_update-pos)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "            pos = pos_update\n",
    "            #print('difference is', pos-pos_before)\n",
    "\n",
    "\n",
    "            if self.mask:\n",
    "                pass;\n",
    "                #pos[batch.ground_node] = pos_old[batch.ground_node]\n",
    "\n",
    "\n",
    "        h = self.pred(h)\n",
    "        superpixel_pos = pos[~batch.ground_node]\n",
    "        superpixel_h = h[~batch.ground_node]\n",
    "        return superpixel_pos, superpixel_h"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:46:16.239618662Z",
     "start_time": "2023-06-26T14:46:16.215660809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph mode:  transformer_3\n"
     ]
    }
   ],
   "source": [
    "# get the dataset\n",
    "cluster_k = 3\n",
    "batch_size = 1\n",
    "data_dir = \"~/Documents/Github/FractalMessagePassing/data/mnist\"\n",
    "subgraph_dict = {\"mode\": \"transformer_3\"}\n",
    "radius = 16\n",
    "transforms = []\n",
    "if radius is not None:\n",
    "    transforms.append(RadiusGraph(radius))\n",
    "    if subgraph_dict is not None:\n",
    "        subgraph_mode = subgraph_dict.get(\"mode\", None)\n",
    "        print(\"Subgraph mode: \", subgraph_mode)\n",
    "        transforms.append(Graph_to_Subgraph(mode=subgraph_mode))\n",
    "    transforms = Compose(transforms)\n",
    "train_val_set = MNISTSuperpixels(root=data_dir, transform=transforms, train=True, cluster_k=cluster_k)\n",
    "train_set = train_val_set[:int(len(train_val_set) * 0.9)]\n",
    "train_set = train_set[:1]\n",
    "val_set = train_val_set[int(len(train_val_set) * 0.9):]\n",
    "val_set = val_set[:1]\n",
    "train_loader = tg.loader.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = tg.loader.DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:47:24.366359112Z",
     "start_time": "2023-06-26T14:47:23.760822358Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# get an optimizer, write a training loop\n",
    "model = Superpixel_EGNN(depth=5,\n",
    "            hidden_features=32,\n",
    "            node_features=4,\n",
    "            out_features=1,\n",
    "            activation=\"relu\",\n",
    "            norm=\"layer\",\n",
    "            aggr=\"sum\",\n",
    "            pool=\"add\",\n",
    "            residual=True,\n",
    "            mask=True,)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# make a model that has a few hidden layers, and a few output layers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T15:48:23.331433625Z",
     "start_time": "2023-06-26T15:48:23.285622590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is  tensor(3.3775, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3771, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3777, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3773, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3773, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3772, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3772, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3773, grad_fn=<SelectBackward0>)\n",
      "loss is  tensor(3.3770, grad_fn=<SelectBackward0>)\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_11744/1233482350.py\", line -1, in <module>\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "    for graph in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = graph.clone()\n",
    "        #print('batch.x is ', batch.x)\n",
    "        #batch.pos = batch.pos + 3*torch.randn_like(batch.pos)\n",
    "        superpixel_pos, superpixel_h = model(batch)\n",
    "        #print(\"first 10 superpixel pos is\", superpixel_pos[:10])\n",
    "        total_h = superpixel_h.sum()\n",
    "        total_h_true = batch.x_full.sum()\n",
    "        total_pos = superpixel_pos.sum()\n",
    "        total_pos_true = batch.pos_full.sum()\n",
    "        diff = superpixel_pos - batch.pos_full\n",
    "        diff = diff**2\n",
    "        loss = sinkhorn_loss(superpixel_pos, batch.pos_full)\n",
    "        #print('superpixel pos is', superpixel_pos)\n",
    "        #print('batch pos is', batch.pos_full)\n",
    "        #loss = criterion(superpixel_pos, batch.pos_full)\n",
    "        #loss = criterion(diff, torch.zeros_like(diff))\n",
    "        #loss = criterion(total_h, total_h_true)\n",
    "        #loss = criterion(total_pos, total_pos_true)\n",
    "        loss.backward()\n",
    "        for name, param in model.named_parameters():\n",
    "            # check if they are not None\n",
    "            if param.grad is not None:\n",
    "                    #print(name, param.grad.data.sum())\n",
    "                    pass\n",
    "        optimizer.step()\n",
    "        #print loss every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print('loss is ', loss)\n",
    "print('Difference between h and true h is', superpixel_h - batch.x_full)\n",
    "print('Superpixel h is', superpixel_h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T15:49:09.034064408Z",
     "start_time": "2023-06-26T15:48:57.943981759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:46:23.796182785Z",
     "start_time": "2023-06-26T14:46:23.789240694Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
