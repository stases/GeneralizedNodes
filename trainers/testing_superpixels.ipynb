{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:31:37.850908663Z",
     "start_time": "2023-06-28T14:31:37.663584026Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable, List, Optional\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from geomloss import SamplesLoss\n",
    "from sklearn.cluster import KMeans\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url, extract_zip\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.transforms import RadiusGraph, Compose\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import wandb\n",
    "from utils.transforms import Graph_to_Subgraph\n",
    "import wandb\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch_geometric.data\n",
    "import torch\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def sinkhorn_loss(x, y):\n",
    "    # \"sinkhorn\" loss ('blur':Ïƒ=0.01, 'scaling':0.9)\n",
    "    loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01, scaling=0.9)\n",
    "    return loss(x, y)\n",
    "\n",
    "def get_datasets(data_dir, batch_size, radius, subgraph_dict=None):\n",
    "    cluster_k = 3\n",
    "    transforms = []\n",
    "    transforms.append(RadiusGraph(radius))\n",
    "    if subgraph_dict is not None:\n",
    "        subgraph_mode = subgraph_dict.get(\"mode\", None)\n",
    "        transforms.append(Graph_to_Subgraph(mode=subgraph_mode))\n",
    "    transforms = Compose(transforms)\n",
    "    # TODO: RESCALE THE DATASET BACK TO THE ORIGINAL SIZE\n",
    "    train_val_set = MNISTSuperpixels(root=data_dir, transform=transforms, train=True, cluster_k=cluster_k)\n",
    "    # split train into train and val sets by taking the last 10% of the training set\n",
    "    train_set = train_val_set[:int(len(train_val_set) * 0.9)]\n",
    "    train_set = train_set[:1]\n",
    "    val_set = train_val_set[int(len(train_val_set) * 0.9):]\n",
    "    val_set = val_set[:1]\n",
    "    test_set = MNISTSuperpixels(root=data_dir, transform=transforms, train=False, cluster_k=cluster_k)\n",
    "    # print which transforms are we using\n",
    "    print(\"Transforms: \", transforms)\n",
    "    #assert len(train_set) + len(val_set) == len(train_val_set)\n",
    "\n",
    "    train_loader = tg.loader.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = tg.loader.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = tg.loader.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor\n",
    "\n",
    "class KMeansClustering(BaseTransform):\n",
    "    def __init__(self, num_clusters):\n",
    "        self.num_clusters = num_clusters\n",
    "\n",
    "    def fit(self, data):\n",
    "        pos = data.pos\n",
    "        x = data.x\n",
    "\n",
    "        N = data.num_nodes\n",
    "        k = N // self.num_clusters\n",
    "\n",
    "        pos_flattened = pos.view(-1, pos.size(-1)).numpy()\n",
    "\n",
    "        kmeans = KMeans(n_clusters=k, n_init=3)\n",
    "        self.labels = kmeans.fit_predict(pos_flattened)\n",
    "        self.labels = torch.from_numpy(self.labels)  # Convert labels to torch.Tensor\n",
    "        self.centroids_pos = torch.zeros(k, pos.size(-1))\n",
    "        self.centroids_x = torch.zeros(k, x.size(-1))\n",
    "\n",
    "        for node_idx, cluster_idx in enumerate(self.labels):\n",
    "            self.centroids_pos[cluster_idx] += pos[node_idx]\n",
    "            self.centroids_x[cluster_idx] += x[node_idx]\n",
    "\n",
    "        for cluster_idx in range(k):\n",
    "            indices = torch.nonzero(self.labels == cluster_idx).view(-1)\n",
    "            count = indices.size(0)\n",
    "\n",
    "            self.centroids_pos[cluster_idx] /= count\n",
    "            self.centroids_x[cluster_idx] /= count\n",
    "\n",
    "    def __call__(self, data):\n",
    "        pos = data.pos\n",
    "        x = data.x\n",
    "\n",
    "        # Assign the precomputed centroids and labels\n",
    "        data.x = self.centroids_x\n",
    "        data.x_full = x\n",
    "        data.pos = self.centroids_pos\n",
    "        data.pos_full = pos\n",
    "        data.cluster_labels = self.labels\n",
    "\n",
    "        return data\n",
    "\n",
    "class MNISTSuperpixels(InMemoryDataset):\n",
    "    url = 'https://data.pyg.org/datasets/MNISTSuperpixels.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        cluster_k: int = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.cluster_k = cluster_k  # Store cluster_k for later use\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        path = self.processed_paths[0] if train else self.processed_paths[1]\n",
    "        self.data, self.slices = torch.load(path)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return 'MNISTSuperpixels.pt'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> List[str]:\n",
    "        if self.cluster_k is None:\n",
    "            return ['train_data.pt', 'test_data.pt']\n",
    "        else:\n",
    "            return [f'train_data_k{self.cluster_k}.pt', f'test_data_k{self.cluster_k}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.raw_dir)\n",
    "        extract_zip(path, self.raw_dir)\n",
    "        os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        inputs = torch.load(self.raw_paths[0])\n",
    "        for i in range(len(inputs)):\n",
    "            data_list = [Data(**data_dict) for data_dict in inputs[i]]\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "            if self.cluster_k is not None:\n",
    "                with tqdm(total=len(data_list), desc=f'Cluster K={self.cluster_k}') as pbar:\n",
    "                    for j in range(len(data_list)):\n",
    "                        cluster_transform = KMeansClustering(num_clusters=self.cluster_k)\n",
    "                        cluster_transform.fit(data_list[j])\n",
    "                        data_list[j] = cluster_transform(data_list[j])\n",
    "                        pbar.update(1)\n",
    "\n",
    "            torch.save(self.collate(data_list), self.processed_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class RFF(nn.Module):\n",
    "    def __init__(self, in_features, out_features, sigma=1.0):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        if out_features % 2 != 0:\n",
    "            self.compensation = 1\n",
    "        else:\n",
    "            self.compensation = 0\n",
    "\n",
    "        B = torch.randn(int(out_features / 2) + self.compensation, in_features) * sigma\n",
    "        B /= math.sqrt(2)\n",
    "        self.register_buffer(\"B\", B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.linear(x, self.B)\n",
    "        x = torch.cat((x.sin(), x.cos()), dim=-1)\n",
    "        if self.compensation:\n",
    "            x = x[..., :-1]\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"in_features={}, out_features={}, sigma={}\".format(\n",
    "            self.in_features, self.out_features, self.sigma\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:31:37.851490390Z",
     "start_time": "2023-06-28T14:31:37.786472275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "#from torch_scatter import scatter_add, scatter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.utils import softmax\n",
    "import math\n",
    "from typing import Optional, Tuple, Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_scatter import scatter\n",
    "import torch_geometric as tg\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.nn.conv import TransformerConv\n",
    "from utils.tools import catch_lone_sender, fully_connected_edge_index\n",
    "\n",
    "class EGNN_FullLayer(tg.nn.MessagePassing):\n",
    "    def __init__(self, emb_dim, activation=\"relu\", norm=\"layer\", aggr=\"add\", RFF_dim=64, RFF_sigma=5, **kwargs):\n",
    "        \"\"\"E(n) Equivariant GNN Layer\n",
    "\n",
    "        Paper: E(n) Equivariant Graph Neural Networks, Satorras et al.\n",
    "\n",
    "        Args:\n",
    "            emb_dim: (int) - hidden dimension `d`\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "        \"\"\"\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "        self.update_pos = True\n",
    "        self.emb_dim = emb_dim\n",
    "        self.RFF_dim = RFF_dim\n",
    "        self.RFF_sigma = RFF_sigma\n",
    "        self.activation = {\"swish\": nn.SiLU(), \"relu\": nn.ReLU()}[activation]\n",
    "        self.norm = {\"layer\": torch.nn.LayerNorm, \"batch\": torch.nn.BatchNorm1d}[norm]\n",
    "\n",
    "        # MLP `\\psi_h` for computing messages `m_ij`\n",
    "        self.mlp_msg = nn.Sequential(\n",
    "             nn.Linear(2 * emb_dim + 1 if self.RFF_dim is None else 2 * emb_dim + RFF_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        # MLP `\\psi_x` for computing messages `\\overrightarrow{m}_ij`\n",
    "        self.mlp_pos = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim), self.norm(emb_dim), self.activation, nn.Linear(emb_dim, 1)\n",
    "        )\n",
    "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
    "        self.mlp_upd = nn.Sequential(\n",
    "            nn.Linear(2 * emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            self.norm(emb_dim),\n",
    "            self.activation,\n",
    "        )\n",
    "        if self.RFF_dim is not None:\n",
    "            self.RFF = RFF(1, RFF_dim, RFF_sigma)\n",
    "    def forward(self, h, pos, edge_index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h: (n, d) - initial node features\n",
    "            pos: (n, 3) - initial node coordinates\n",
    "            edge_index: (e, 2) - pairs of edges (i, j)\n",
    "        Returns:\n",
    "            out: [(n, d),(n,3)] - updated node features\n",
    "        \"\"\"\n",
    "        out = self.propagate(edge_index, h=h, pos=pos)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, pos_i, pos_j):\n",
    "        # Compute messages\n",
    "        pos_diff = pos_i - pos_j\n",
    "        dists = torch.norm(pos_diff, dim=-1).unsqueeze(1)\n",
    "        if self.RFF_dim is not None:\n",
    "            #print(\"USING RFF\")\n",
    "            dists = self.RFF(dists)\n",
    "        msg = torch.cat([h_i, h_j, dists], dim=-1)\n",
    "        msg = self.mlp_msg(msg)\n",
    "        # Scale magnitude of displacement vector\n",
    "        pos_diff = pos_diff * self.mlp_pos(msg)  # torch.clamp(updates, min=-100, max=100)\n",
    "        return msg, pos_diff\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        msgs, pos_diffs = inputs\n",
    "\n",
    "        # Aggregate messages\n",
    "        msg_aggr = scatter(msgs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "        # Aggregate displacement vectors\n",
    "        if self.update_pos:\n",
    "            pos_aggr = scatter(pos_diffs, index, dim=self.node_dim, reduce=\"mean\")\n",
    "\n",
    "        nodes_to_upd = torch.unique(index)\n",
    "        msg_aggr = msg_aggr[nodes_to_upd]\n",
    "\n",
    "        if self.update_pos:\n",
    "            pos_aggr = pos_aggr[nodes_to_upd]\n",
    "        else:\n",
    "            pos_aggr = None\n",
    "\n",
    "        return msg_aggr, pos_aggr, nodes_to_upd\n",
    "\n",
    "    def update(self, aggr_out, h, pos):\n",
    "        msg_aggr, pos_aggr, nodes_to_upd = aggr_out\n",
    "\n",
    "        upd_out = h\n",
    "        upd_out[nodes_to_upd] = self.mlp_upd(torch.cat([h[nodes_to_upd], msg_aggr], dim=-1))\n",
    "        if self.update_pos:\n",
    "            upd_pos = pos\n",
    "            #print('pos before is ', pos)\n",
    "            #print('pos aggr is ', pos_aggr)\n",
    "            upd_pos[nodes_to_upd] = pos[nodes_to_upd] + pos_aggr\n",
    "            # print the difference\n",
    "            #print('pos after is ', upd_pos)\n",
    "\n",
    "        else:\n",
    "            upd_pos = pos\n",
    "\n",
    "        return upd_out, upd_pos\n",
    "\n",
    "\n",
    "class Superpixel_EGNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            depth=5,\n",
    "            hidden_features=128,\n",
    "            node_features=1,\n",
    "            out_features=1,\n",
    "            activation=\"relu\",\n",
    "            norm=\"layer\",\n",
    "            aggr=\"sum\",\n",
    "            pool=\"add\",\n",
    "            residual=True,\n",
    "            mask=True,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Name of the network\n",
    "        self.name = \"Superpixel_EGNN\"\n",
    "        self.depth = depth\n",
    "        # Embedding lookup for initial node features\n",
    "        self.emb_in = nn.Linear(node_features, hidden_features)\n",
    "\n",
    "        # Stack of GNN layers\n",
    "        self.ground_mps = torch.nn.ModuleList()\n",
    "        self.ground_to_sub_mps = torch.nn.ModuleList()\n",
    "        self.sub_mps = torch.nn.ModuleList()\n",
    "        self.sub_to_ground_mps = torch.nn.ModuleList()\n",
    "        for layer in range(depth):\n",
    "            self.ground_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "            self.ground_to_sub_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "            self.sub_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "            #self.sub_to_ground_mps.append(EGNN_FullLayer(hidden_features, activation, norm, aggr))\n",
    "        self.residual = residual\n",
    "        self.mask = mask\n",
    "\n",
    "        self.pred = torch.nn.Sequential(\n",
    "        torch.nn.Linear(hidden_features*1, hidden_features),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "    def forward(self, batch):\n",
    "\n",
    "        h = self.emb_in(batch.x)  # (n,) -> (n, d)\n",
    "        pos = batch.pos.clone()  # (n, 3)\n",
    "        pos[~batch.ground_node] += torch.randn_like(pos[~batch.ground_node]) * 0.01\n",
    "        h_ground = h[batch.ground_node]\n",
    "        pos_ground = pos[batch.ground_node]\n",
    "\n",
    "        h_sub = h[~batch.ground_node]\n",
    "        pos_sub = pos[~batch.ground_node]\n",
    "\n",
    "        '''h_update, pos_update = conv(h, pos, batch.edge_index)\n",
    "\n",
    "            # Update node features (n, d) -> (n, d)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "\n",
    "            # Update node coordinates (no residual) (n, 3) -> (n, 3)\n",
    "            pos = pos_update'''\n",
    "\n",
    "        for layer_idx in range(self.depth):\n",
    "            h_old = h.clone()\n",
    "            h_0 = h\n",
    "            pos_old = pos.clone()\n",
    "            h_update, pos_update = self.ground_mps[layer_idx](h, pos, batch.edge_index)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "            pos = pos_update\n",
    "            if self.mask:\n",
    "                pos[batch.ground_node] = pos_old[batch.ground_node]\n",
    "\n",
    "            pos_old = pos.clone()\n",
    "            h_update, pos_update = self.ground_to_sub_mps[layer_idx](h, pos, batch.node_subnode_index)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "            pos = pos_update\n",
    "            if self.mask:\n",
    "                pos[batch.ground_node] = pos_old[batch.ground_node]\n",
    "            pos_old = pos.clone()\n",
    "\n",
    "            pos_before = pos.clone()\n",
    "            h_update, pos_update = self.sub_mps[layer_idx](h, pos, batch.subgraph_edge_index)\n",
    "            #print('pos update is', pos_update)\n",
    "            #print('difference is', pos_update-pos)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "            pos = pos_update\n",
    "            #print('difference is', pos-pos_before)\n",
    "\n",
    "\n",
    "            if self.mask:\n",
    "                pass;\n",
    "                #pos[batch.ground_node] = pos_old[batch.ground_node]\n",
    "\n",
    "\n",
    "        h = self.pred(h)\n",
    "        #superpixel_pos = pos[~batch.ground_node]\n",
    "        #superpixel_h = h[~batch.ground_node]\n",
    "        return pos, h"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:31:37.851990103Z",
     "start_time": "2023-06-28T14:31:37.787016567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class EGNN_Full(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            depth=5,\n",
    "            hidden_features=128,\n",
    "            node_features=1,\n",
    "            out_features=1,\n",
    "            activation=\"relu\",\n",
    "            norm=\"layer\",\n",
    "            aggr=\"sum\",\n",
    "            RFF_dim=None,\n",
    "            RFF_sigma=None,\n",
    "            pool=\"add\",\n",
    "            residual=True,\n",
    "            return_pos=False,\n",
    "            **kwargs\n",
    "    ):\n",
    "        \"\"\"E(n) Equivariant GNN model\n",
    "\n",
    "        Args:\n",
    "            depth: (int) - number of message passing layers\n",
    "            hidden_features: (int) - hidden dimension\n",
    "            node_features: (int) - initial node feature dimension\n",
    "            out_features: (int) - output number of classes\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "            pool: (str) - global pooling function (sum/mean)\n",
    "            residual: (bool) - whether to use residual connections\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Name of the network\n",
    "        self.name = \"EGNN_Full\"\n",
    "\n",
    "        # Embedding lookup for initial node features\n",
    "        self.emb_in = nn.Linear(node_features, hidden_features)\n",
    "\n",
    "        # Stack of GNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(depth):\n",
    "            self.convs.append(EGNN_FullLayer(hidden_features, activation, norm, aggr, RFF_dim, RFF_sigma))\n",
    "\n",
    "        # Global pooling/readout function\n",
    "        self.pool = {\"mean\": tg.nn.global_mean_pool, \"add\": tg.nn.global_add_pool, \"none\": None}[pool]\n",
    "\n",
    "        # Predictor MLP\n",
    "        self.pred = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "        self.residual = residual\n",
    "        self.return_pos = return_pos\n",
    "\n",
    "    def forward(self, batch):\n",
    "        h = self.emb_in(batch.x)  # (n,) -> (n, d)\n",
    "        pos = batch.pos.clone()  # (n, 3)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, batch.edge_index)\n",
    "\n",
    "            # Update node features (n, d) -> (n, d)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "\n",
    "            # Update node coordinates (no residual) (n, 3) -> (n, 3)\n",
    "            pos = pos_update\n",
    "        if self.pool is not None:\n",
    "            out = self.pool(h, batch.batch)  # (n, d) -> (batch_size, d)\n",
    "        else:\n",
    "            out = h\n",
    "\n",
    "        if self.return_pos:\n",
    "            return pos, self.pred(out)\n",
    "        else:\n",
    "            return self.pred(out)  # (batch_size, out_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:31:37.863648190Z",
     "start_time": "2023-06-28T14:31:37.860545248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def visualize_sample(input_graph, output_graph, target_graph, mode):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(36, 12))\n",
    "\n",
    "    # For the input graph\n",
    "    sample_graph = input_graph\n",
    "    sample_graph.pos -= sample_graph.pos.min()\n",
    "    sample_graph.pos = sample_graph.pos/sample_graph.pos.max() * 2 - 1\n",
    "    pos_dict = {}\n",
    "    for i, p in enumerate(sample_graph.pos):\n",
    "        pos_dict[i] = p.detach().numpy() * np.array([1, -1])\n",
    "    g = to_networkx(sample_graph, to_undirected=True)\n",
    "    # Set the sample graph.x to all have value equal to 1\n",
    "    nx.draw_networkx_nodes(g,\n",
    "                           node_size=500,\n",
    "                           node_color=sample_graph.x.detach().cpu().numpy(),\n",
    "                           node_shape=r'$\\circ$',\n",
    "                           pos=pos_dict,\n",
    "                           cmap='Purples',\n",
    "                           ax=axs[0])\n",
    "    nx.draw_networkx_edges(g, edge_color='r', alpha=0.5, pos=pos_dict, ax=axs[0])\n",
    "    axs[0].set_title('Input Graph', fontsize=25)\n",
    "\n",
    "    # For the output graph\n",
    "    sample_graph = output_graph\n",
    "    sample_graph.pos -= sample_graph.pos.min()\n",
    "    sample_graph.pos = sample_graph.pos/sample_graph.pos.max() * 2 - 1\n",
    "    pos_dict = {}\n",
    "    for i, p in enumerate(sample_graph.pos):\n",
    "        pos_dict[i] = p.detach().numpy() * np.array([1, -1])\n",
    "    g = to_networkx(sample_graph, to_undirected=True)\n",
    "    nx.draw_networkx_nodes(g,\n",
    "                           node_size=500,\n",
    "                           node_color=sample_graph.x.detach().cpu().numpy(),\n",
    "                           node_shape=r'$\\circ$',\n",
    "                           pos=pos_dict,\n",
    "                           cmap='Purples',\n",
    "                           ax=axs[1])\n",
    "    nx.draw_networkx_edges(g, edge_color='r', alpha=0.5, pos=pos_dict, ax=axs[1])\n",
    "    axs[1].set_title('Output Graph', fontsize=25)\n",
    "\n",
    "    # For the target graph\n",
    "    sample_graph = target_graph\n",
    "    sample_graph.pos -= sample_graph.pos.min()\n",
    "    sample_graph.pos = sample_graph.pos/sample_graph.pos.max() * 2 - 1\n",
    "    pos_dict = {}\n",
    "    for i, p in enumerate(sample_graph.pos):\n",
    "        pos_dict[i] = p.detach().numpy() * np.array([1, -1])\n",
    "    g = to_networkx(sample_graph, to_undirected=True)\n",
    "    nx.draw_networkx_nodes(g,\n",
    "                           node_size=500,\n",
    "                           node_color=sample_graph.x.detach().cpu().numpy(),\n",
    "                           node_shape=r'$\\circ$',\n",
    "                           pos=pos_dict,\n",
    "                           cmap='Purples',\n",
    "                           ax=axs[2])\n",
    "    nx.draw_networkx_edges(g, edge_color='r', alpha=0.5, pos=pos_dict, ax=axs[2])\n",
    "    axs[2].set_title('Target Graph', fontsize=25)\n",
    "    plt.show()\n",
    "    # Convert the figure to an image\n",
    "    #wandb_image = wandb.Image(fig)\n",
    "\n",
    "    # Log the image using WandB\n",
    "    plt.close(fig)\n",
    "\n",
    "def extract_graph(data, graph_id):\n",
    "    device = 'cpu'\n",
    "\n",
    "    # Get mask of nodes that belong to the graph_id\n",
    "    node_mask = data.batch == graph_id\n",
    "    node_mask = node_mask.to(device)\n",
    "    # Extract node attributes\n",
    "    x = None\n",
    "    pos = None\n",
    "    if data.x is not None:\n",
    "        x = data.x[node_mask]\n",
    "    if data.pos is not None:\n",
    "        pos = data.pos[node_mask]\n",
    "\n",
    "    x = x.to(device)\n",
    "    pos = pos.to(device)\n",
    "\n",
    "    # Create a mapping from old node indices to new node indices\n",
    "    node_index_mapping = torch.full((data.batch.size(0), ), -1, dtype=torch.long, device=device).to(device)\n",
    "    node_index_mapping[node_mask] = torch.arange(node_mask.sum().item(), dtype=torch.long)\n",
    "\n",
    "    # Get mask of edges that belong to the graph_id\n",
    "    node_mask = node_mask.to(device)\n",
    "    data.edge_index = data.edge_index.to(device)\n",
    "    edge_mask = node_mask[data.edge_index[0]] & node_mask[data.edge_index[1]].to(device)\n",
    "\n",
    "    # Extract edge attributes\n",
    "    edge_index = None\n",
    "    if data.edge_index is not None:\n",
    "        edge_index = node_index_mapping[data.edge_index[:, edge_mask]].to(device)\n",
    "\n",
    "    # Create single graph data\n",
    "    single_graph_data = torch_geometric.data.Data(x=x, edge_index=edge_index, pos=pos)\n",
    "\n",
    "    return single_graph_data\n",
    "\n",
    "def prepare_sample(batch, superpixel_pos, superpixel_h, radius=8):\n",
    "    input_data = Data(x=batch.x[batch.ground_node][:, 0].unsqueeze(-1), pos=batch.pos[batch.ground_node],\n",
    "                      batch=batch.batch[batch.ground_node], y=batch.y)\n",
    "    input_data = RadiusGraph(radius)(input_data)\n",
    "\n",
    "    output_data = Data(x=superpixel_h, pos=superpixel_pos, batch=batch.batch[~batch.ground_node], y=batch.y)\n",
    "    output_data = RadiusGraph(radius)(output_data)\n",
    "\n",
    "    target_data = Data(pos=batch.pos_full, x=batch.x_full, edge_index=batch.edge_index,\n",
    "                       batch=batch.batch[~batch.ground_node], y=batch.y)\n",
    "    target_data = RadiusGraph(radius)(target_data)\n",
    "    return input_data, output_data, target_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:31:37.888599859Z",
     "start_time": "2023-06-28T14:31:37.874824256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def fully_connected_edge_index(num_nodes):\n",
    "    # Create a tensor with all possible combinations of node indices\n",
    "    all_edges = torch.combinations(torch.arange(num_nodes), r=2)\n",
    "\n",
    "    # Create a tensor for the reverse edges (since it's an undirected graph)\n",
    "    reverse_edges = all_edges.flip(1)\n",
    "\n",
    "    # Concatenate both sets of edges to get a fully connected edge index\n",
    "    edge_index = torch.cat((all_edges, reverse_edges), dim=0).t().contiguous()\n",
    "\n",
    "    return edge_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:31:37.934277746Z",
     "start_time": "2023-06-28T14:31:37.887074586Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph mode:  transformer_3\n"
     ]
    }
   ],
   "source": [
    "# get the dataset\n",
    "cluster_k = 3\n",
    "batch_size = 4\n",
    "data_dir = \"~/Documents/Github/FractalMessagePassing/data/mnist\"\n",
    "subgraph_dict = {\"mode\": \"transformer_3\"}\n",
    "radius = 16\n",
    "transforms = []\n",
    "if radius is not None:\n",
    "    transforms.append(RadiusGraph(radius))\n",
    "    if subgraph_dict is not None:\n",
    "        subgraph_mode = subgraph_dict.get(\"mode\", None)\n",
    "        print(\"Subgraph mode: \", subgraph_mode)\n",
    "        transforms.append(Graph_to_Subgraph(mode=subgraph_mode))\n",
    "    transforms = Compose(transforms)\n",
    "train_val_set = MNISTSuperpixels(root=data_dir, transform=transforms, train=True, cluster_k=cluster_k)\n",
    "train_set = train_val_set[:int(len(train_val_set) * 0.9)]\n",
    "train_set = train_set[:4]\n",
    "val_set = train_val_set[int(len(train_val_set) * 0.9):]\n",
    "val_set = val_set[:1]\n",
    "train_loader = tg.loader.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "val_loader = tg.loader.DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:55:00.387663938Z",
     "start_time": "2023-06-28T14:54:59.751957100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# get an optimizer, write a training loop\n",
    "model = Superpixel_EGNN(depth=2,\n",
    "            hidden_features=64,\n",
    "            node_features=4,\n",
    "            out_features=1,\n",
    "            activation=\"relu\",\n",
    "            norm=\"layer\",\n",
    "            aggr=\"sum\",\n",
    "            pool=\"none\",\n",
    "            residual=True,\n",
    "            mask=False,)\n",
    "model_2 = EGNN_Full(depth=2,\n",
    "            hidden_features=64,\n",
    "            node_features=4,\n",
    "            out_features=1,\n",
    "            RFF_dim=64,\n",
    "            RFF_sigma=5,\n",
    "            activation=\"relu\",\n",
    "            norm=\"layer\",\n",
    "            aggr=\"sum\",\n",
    "            pool=\"none\",\n",
    "            residual=True,\n",
    "            return_pos=True,\n",
    "            mask=True,)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# make a model that has a few hidden layers, and a few output layers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:55:00.886726770Z",
     "start_time": "2023-06-28T14:55:00.867192493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True h shape is torch.Size([4, 75, 1])\n",
      "Superpixel h shape is torch.Size([4, 75, 1])\n",
      "True pos shape is torch.Size([4, 75, 2])\n",
      "Superpixel pos shape is torch.Size([4, 75, 2])\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[79], line 53\u001B[0m\n\u001B[1;32m     46\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_pos \u001B[38;5;241m+\u001B[39m loss_h\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m#print('superpixel pos is', superpixel_pos)\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m#print('batch pos is', batch.pos_full)\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m#loss = criterion(superpixel_pos, batch.pos_full)\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m#loss = criterion(diff, torch.zeros_like(diff))\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m#loss = criterion(total_h, total_h_true)\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m#loss = criterion(total_pos, total_pos_true)\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mnamed_parameters():\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;66;03m# check if they are not None\u001B[39;00m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m param\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     57\u001B[0m             \u001B[38;5;66;03m#print(name, param.grad.data.sum())\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for graph in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch = graph.clone()\n",
    "        batch_max = torch.max(batch.batch)+1\n",
    "        # Make a fully connected batch index\n",
    "        #batch.edge_index = fully_connected_edge_index(batch.num_nodes)\n",
    "        #print('batch.x is ', batch.x)\n",
    "        #batch.pos = batch.pos + 3*torch.randn_like(batch.pos)\n",
    "        batch.edge_index = to_undirected(batch.edge_index)\n",
    "        batch.node_subnode_index = to_undirected(batch.node_subnode_index)\n",
    "        superpixel_pos, superpixel_h = model(batch)\n",
    "        print(superpixel_pos.requires_grad)\n",
    "        print(superpixel_h.requires_grad)\n",
    "        superpixel_pos = superpixel_pos[~batch.ground_node]\n",
    "        superpixel_h = superpixel_h[~batch.ground_node]\n",
    "        graph.batch = graph.batch[~batch.ground_node]\n",
    "\n",
    "        superpixel_pos = superpixel_pos.view(batch_max, -1, 2)\n",
    "        superpixel_h = superpixel_h.view(batch_max, -1, 1)\n",
    "        true_pos = graph.pos_full.view(batch_max, -1, 2)\n",
    "        true_h = graph.x_full.view(batch_max, -1, 1)\n",
    "        print(\"True h shape is\", true_h.shape)\n",
    "        print(\"Superpixel h shape is\", superpixel_h.shape)\n",
    "        print(\"True pos shape is\", true_pos.shape)\n",
    "        print(\"Superpixel pos shape is\", superpixel_pos.shape)\n",
    "\n",
    "        #print(\"first 10 superpixel pos is\", superpixel_pos[:10])\n",
    "        #total_h = superpixel_h.sum()\n",
    "        #total_h_true = batch.x_full.sum()\n",
    "        #total_pos = superpixel_pos.sum()\n",
    "        #total_pos_true = batch.pos_full.sum()\n",
    "        #diff = superpixel_pos - batch.pos_full\n",
    "        #diff = diff**2\n",
    "        #loss_pos = sinkhorn_loss(superpixel_pos, batch.pos_full)\n",
    "        #loss_pos = criterion(diff, torch.zeros_like(diff))\n",
    "        loss_h = criterion(superpixel_h, true_h)\n",
    "        #loss_h = criterion(total_h, total_h_true)\n",
    "        loss_pos = criterion(superpixel_pos, true_pos)\n",
    "        print(superpixel_pos.requires_grad)\n",
    "        print(superpixel_h.requires_grad)\n",
    "        loss = loss_pos + loss_h\n",
    "        #print('superpixel pos is', superpixel_pos)\n",
    "        #print('batch pos is', batch.pos_full)\n",
    "        #loss = criterion(superpixel_pos, batch.pos_full)\n",
    "        #loss = criterion(diff, torch.zeros_like(diff))\n",
    "        #loss = criterion(total_h, total_h_true)\n",
    "        #loss = criterion(total_pos, total_pos_true)\n",
    "        loss.backward()\n",
    "        for name, param in model.named_parameters():\n",
    "            # check if they are not None\n",
    "            if param.grad is not None:\n",
    "                    #print(name, param.grad.data.sum())\n",
    "                    pass\n",
    "        optimizer.step()\n",
    "        #print loss every 10 epochs\n",
    "        if epoch % 50 == 0:\n",
    "            print('loss is ', loss)\n",
    "            idx=1\n",
    "            input_data, output_data, target_data = prepare_sample(batch, superpixel_pos, superpixel_h)\n",
    "            #print('input data is', input_data)\n",
    "            #print('output data is', output_data)\n",
    "            #print('target data is', target_data)\n",
    "            input_graph = extract_graph(input_data, idx)\n",
    "            output_graph = extract_graph(output_data, idx)\n",
    "            target_graph = extract_graph(target_data, idx)\n",
    "            visualize_sample(input_graph, output_graph, target_graph, \"train\")\n",
    "#print('Difference between h and true h is', superpixel_h - batch.x_full)\n",
    "#print('Superpixel h is', superpixel_h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T14:55:06.568474878Z",
     "start_time": "2023-06-28T14:55:06.496359496Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
