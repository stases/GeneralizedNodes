model_arch: Transformer_MPNN
depth: 4
ascend_depth: 0
num_heads: 2
num_ascend_heads: 0
pool: "add"
sub_aggr: "mean"
only_ground: False
only_sub: True
residual: True
norm: "layer"
mask: True
subgraph_dict:
  mode: "transformer_4"
trainer: mnist
learning_rate: 0.0005
radius: 8
RFF_dim: null
RFF_sigma: null
epochs: 70
warmup_epochs: 5
batch_size: 64
fully_connect: False
hidden_features: 48
edge_features: 0
node_features: 5
out_features: 10
data_dir: "./data/mnist"
model_dir: "./trained/mnist"
log_dir: "./logs"
optimizer:
  name: Adam
  kwargs:
    betas: [0.9, 0.999]
    eps: 1e-8
criterion:
  name: L1Loss
scheduler:
  name: CosineAnnealingLR
  kwargs:
    T_max: ${epochs}
device: cuda
