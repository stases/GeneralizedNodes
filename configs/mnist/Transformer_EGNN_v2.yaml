model_arch: Transformer_EGNN_v2
depth: 3
ascend_depth: 0
num_heads: 1
num_ascend_heads: 0
pool: "add"
sub_aggr: "mean"
only_ground: False
only_sub: True
residual: False
norm: "layer"
mask: True
trainer: mnist
radius: 8
learning_rate: 0.0008
RFF_dim: 96
RFF_sigma: 10
epochs: 70
warmup_epochs: 5
batch_size: 64
subgraph_dict:
  mode: "transformer_4"
node_features: 5
fully_connect: False
edge_features: 0
hidden_features: 48
out_features: 10
data_dir: "./data/mnist"
model_dir: "./trained/mnist"
log_dir: "./logs"
optimizer:
  name: Adam
  kwargs:
    betas: [0.9, 0.999]
    eps: 1e-8
criterion:
  name: L1Loss
scheduler:
  name: CosineAnnealingLR
  kwargs:
    T_max: ${epochs}
device: cuda
