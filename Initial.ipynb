{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import QM9 dataset\n",
    "from torch_geometric.datasets import QM9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# load some data from QM9\n",
    "data = QM9('~/data/QM9') # this will download the dataset if it is not already present\n",
    "sample_data = data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Subgraph:\n",
    "    def __init__(self, graph, depth=1):\n",
    "        self.num_nodes = graph.x.shape[0]\n",
    "        self.subgraph = graph.clone()\n",
    "\n",
    "    def convert_to_subgraph(self):\n",
    "        self.add_subnode_features()\n",
    "        self.add_node_flags()\n",
    "        self.add_subnode_edges()\n",
    "        self.add_node_subnode_edges()\n",
    "        self.add_subgraph_batch_index()\n",
    "        return self.subgraph\n",
    "\n",
    "    def add_subnode_features(self):\n",
    "        self.subgraph.x = self.subgraph.x.repeat(self.num_nodes+1,1)\n",
    "        self.total_num_nodes = self.subgraph.x.shape[0]\n",
    "\n",
    "    def add_node_flags(self):\n",
    "        if hasattr(self.subgraph, 'x'):\n",
    "            self.subgraph.ground_node = torch.arange(self.subgraph.x.shape[0]) < self.num_nodes\n",
    "        else:\n",
    "            print('No node features found. Please add node features first.')\n",
    "\n",
    "    def add_subnode_edges(self):\n",
    "        self.subgraph.subgraph_edge_index = self.subgraph.edge_index + self.num_nodes\n",
    "        for subg in range(self.num_nodes):\n",
    "            self.subgraph.subgraph_edge_index = torch.cat([self.subgraph.subgraph_edge_index, self.subgraph.edge_index + (subg+1)*self.num_nodes], dim=1)\n",
    "\n",
    "    def add_node_subnode_edges(self):\n",
    "        self.subgraph.node_subnode_index = torch.stack([torch.arange(self.num_nodes).repeat_interleave(self.num_nodes), torch.arange(self.num_nodes, self.total_num_nodes)], dim=0)\n",
    "\n",
    "    def add_subgraph_batch_index(self):\n",
    "        self.subgraph.subgraph_batch_index = torch.arange(self.num_nodes).repeat_interleave(self.num_nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FractalMP(tg.nn.MessagePassing):\n",
    "    \"\"\"Message Passing Neural Network Layer\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_features,\n",
    "        edge_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "        aggr=\"add\",\n",
    "        act=nn.ReLU,\n",
    "        edge_inference=False,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr)\n",
    "        self.edge_inference = edge_inference\n",
    "        self.message_net = nn.Sequential(\n",
    "            nn.Linear(2 * node_features + edge_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Linear(node_features + hidden_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, out_features),\n",
    "        )\n",
    "\n",
    "        if edge_inference:\n",
    "            self.edge_inferrer = nn.Sequential(\n",
    "                nn.Linear(hidden_features, 1), nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, ground_node, subgraph_batch_index, edge_attr=None):\n",
    "        \"\"\"Propagate\"\"\"\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(node_subnode_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(subgraph_edge_index, x=x, edge_attr=edge_attr)\n",
    "        # global pool over nodes whose ground node is false\n",
    "        x[ground_node] = tg.nn.global_mean_pool(x[~ground_node], subgraph_batch_index)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"Send message with edge attributes\"\"\"\n",
    "        input = [x_i, x_j, edge_attr]\n",
    "        input = [val for val in input if val is not None]\n",
    "        input = torch.cat(input, dim=-1)\n",
    "        message = self.message_net(input)\n",
    "\n",
    "        if self.edge_inference:\n",
    "            message = message * self.edge_inferrer(message)\n",
    "        return message\n",
    "\n",
    "    def update(self, message, x):\n",
    "        \"\"\"Update node\"\"\"\n",
    "        input = torch.cat((x, message), dim=-1)\n",
    "        update = self.update_net(input)\n",
    "        return update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class FractalNet(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.fractal_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.fractal_mps.append(FractalMP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        x = self.embedding(x)\n",
    "        for i in range(self.depth):\n",
    "            x = self.fractal_mps[i](x, edge_index, subgraph_edge_index, node_subnode_index, ground_node, subgraph_batch_index, edge_attr)\n",
    "        x = self.output(x)\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "sample_graph = Subgraph(sample_data).convert_to_subgraph()\n",
    "node_features = sample_graph.x.shape[1]\n",
    "edge_features = 0\n",
    "hidden_features = 64\n",
    "out_features = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# create a fractal net and train it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FractalNet(node_features, edge_features, hidden_features, out_features, depth=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "LABEL_INDEX = 7\n",
    "def get_qm9(data_dir, device=\"cuda\"):\n",
    "    \"\"\"Download the QM9 dataset from pytorch geometric. Put it onto the device. Split it up into train / validation / test.\n",
    "    Args:\n",
    "        data_dir: the directory to store the data.\n",
    "        device: put the data onto this device.\n",
    "    Returns:\n",
    "        train dataset, validation dataset, test dataset.\n",
    "    \"\"\"\n",
    "    dataset = QM9(data_dir)\n",
    "\n",
    "    # Permute the dataset\n",
    "    try:\n",
    "        permu = torch.load(\"permute.pt\")\n",
    "        dataset = dataset[permu]\n",
    "    except FileNotFoundError:\n",
    "        warn(\"Using non-standard permutation since permute.pt does not exist.\")\n",
    "        dataset, _ = dataset.shuffle(return_perm=True)\n",
    "\n",
    "    # z score / standard score targets to mean = 0 and std = 1.\n",
    "    mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "    std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "    dataset.data.y = (dataset.data.y - mean) / std\n",
    "    mean, std = mean[:, LABEL_INDEX].item(), std[:, LABEL_INDEX].item()\n",
    "\n",
    "    # Move the data to the device (it should fit on lisa gpus)\n",
    "    dataset.data = dataset.data.to(device)\n",
    "\n",
    "    len_train = 100_000\n",
    "    len_val = 10_000\n",
    "\n",
    "    train = dataset[:len_train]\n",
    "    valid = dataset[len_train : len_train + len_val]\n",
    "    test = dataset[len_train + len_val :]\n",
    "\n",
    "    assert len(dataset) == len(train) + len(valid) + len(test)\n",
    "\n",
    "    return train, valid, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-b2345eba1c4f>:18: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n"
     ]
    }
   ],
   "source": [
    "# create a dataloader for qm9\n",
    "from torch_geometric.loader import DataLoader\n",
    "dataset , _ ,_  = get_qm9(\"data/qm9\", device=device)\n",
    "# take a subset of the dataset\n",
    "dataset = dataset[:1000]\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9ed0324b8d44f9dbf72aafaa1be8d25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.0402429077640636\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "173cc4198af34df0a1e050494987f9be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.9551820499933509\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37f5a5d904004f378ea9fd0651f483a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.8987012124667024\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31b3109560ba4c41901cfaf3454a2841"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.9026593807928802\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4fd3ff24146436fa68ba3b2acf652ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.8925886963500979\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e42096866d0a46a088b63c50b43f7c92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.8683935219835505\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dba58d7436e445d08a77b35fd244945c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.7846923819308054\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dddcf6b14ff94a559d065d2135b305d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.825826865932264\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3eb382bc775c4398818fb31c79b680c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.7890269650978861\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6443023a1704490a47a34397ab1c548"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.7157069895064606\n"
     ]
    }
   ],
   "source": [
    "# start training the model\n",
    "# import tqdm to track progress of loss\n",
    "import tqdm.notebook as tqdm\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        data = Subgraph(data).convert_to_subgraph().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target = data.y[:, LABEL_INDEX]\n",
    "        out = model(data.x, data.edge_index, data.subgraph_edge_index, data.node_subnode_index, data.ground_node, data.subgraph_batch_index, data.batch)\n",
    "        loss = criterion(out.mean(), target.mean())\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # show loss on tqdm\n",
    "        #tqdm.tqdm.write(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss/len(loader)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MISC\n",
    "def graph_to_subgraph(graph, depth=1):\n",
    "    num_nodes = graph.x.shape[0]\n",
    "    subgraph = graph.clone()\n",
    "    subgraph.x = subgraph.x.repeat(num_nodes+1,1) # Initialize subnodes by concatenation\n",
    "    total_num_nodes = subgraph.x.shape[0]\n",
    "    ground_node = torch.arange(subgraph.x.shape[0]) < num_nodes # Mask for whether the node is a subnode or not\n",
    "    subgraph.ground_node = ground_node # Add to the Data object\n",
    "    # Create subgraph edge index which is same as edge index but for every subgraph\n",
    "    subgraph.subgraph_edge_index = subgraph.edge_index + num_nodes\n",
    "    for subg in range(num_nodes):\n",
    "        subgraph.subgraph_edge_index = torch.cat([subgraph.subgraph_edge_index, subgraph.edge_index + (subg+1)*num_nodes], dim=1)\n",
    "    # Create edge index for directed edges between ground node and it's subnodes\n",
    "    subgraph.interaction_index = torch.stack([torch.arange(num_nodes).repeat_interleave(num_nodes), torch.arange(num_nodes, total_num_nodes)], dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}