{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import tqdm.notebook as tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "# import QM9 dataset\n",
    "from torch_geometric.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# load some data from QM9\n",
    "data = QM9('~/data/QM9') # this will download the dataset if it is not already present\n",
    "sample_data = data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Subgraph:\n",
    "    def __init__(self, graph, depth=1):\n",
    "        self.num_nodes = graph.x.shape[0]\n",
    "        self.subgraph = graph.clone()\n",
    "\n",
    "    def convert_to_subgraph(self):\n",
    "        self.add_subnode_features()\n",
    "        self.add_node_flags()\n",
    "        self.add_subnode_edges()\n",
    "        self.add_node_subnode_edges()\n",
    "        self.add_subnode_node_edges()\n",
    "        self.add_subgraph_batch_index()\n",
    "        return self.subgraph\n",
    "\n",
    "    def add_subnode_features(self):\n",
    "        self.subgraph.x = self.subgraph.x.repeat(self.num_nodes+1,1)\n",
    "        self.total_num_nodes = self.subgraph.x.shape[0]\n",
    "\n",
    "    def add_node_flags(self):\n",
    "        if hasattr(self.subgraph, 'x'):\n",
    "            self.subgraph.ground_node = torch.arange(self.subgraph.x.shape[0]) < self.num_nodes\n",
    "        else:\n",
    "            print('No node features found. Please add node features first.')\n",
    "\n",
    "    def add_subnode_edges(self):\n",
    "        self.subgraph.subgraph_edge_index = self.subgraph.edge_index + self.num_nodes\n",
    "        for subg in range(self.num_nodes):\n",
    "            self.subgraph.subgraph_edge_index = torch.cat([self.subgraph.subgraph_edge_index, self.subgraph.edge_index + (subg+1)*self.num_nodes], dim=1)\n",
    "\n",
    "    def add_node_subnode_edges(self):\n",
    "        self.subgraph.node_subnode_index = torch.stack([torch.arange(self.num_nodes).repeat_interleave(self.num_nodes), torch.arange(self.num_nodes, self.total_num_nodes)], dim=0)\n",
    "\n",
    "    def add_subnode_node_edges(self):\n",
    "        self.subgraph.subnode_node_index = torch.stack([torch.arange(self.num_nodes, self.total_num_nodes), torch.arange(self.num_nodes).repeat_interleave(self.num_nodes)], dim=0)\n",
    "\n",
    "    def add_subgraph_batch_index(self):\n",
    "        self.subgraph.subgraph_batch_index = torch.arange(self.num_nodes).repeat_interleave(self.num_nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FractalMP(tg.nn.MessagePassing):\n",
    "    \"\"\"Message Passing Neural Network Layer\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_features,\n",
    "        edge_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "        aggr=\"add\",\n",
    "        act=nn.ReLU,\n",
    "        edge_inference=False,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr)\n",
    "        self.edge_inference = edge_inference\n",
    "        self.message_net = nn.Sequential(\n",
    "            nn.Linear(2 * node_features + edge_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Linear(node_features + hidden_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, out_features),\n",
    "        )\n",
    "\n",
    "        if edge_inference:\n",
    "            self.edge_inferrer = nn.Sequential(\n",
    "                nn.Linear(hidden_features, 1), nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, edge_attr=None):\n",
    "        \"\"\"Propagate\"\"\"\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(node_subnode_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(subgraph_edge_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(subnode_node_index, x=x, edge_attr=edge_attr)\n",
    "        # global pool over nodes whose ground node is false\n",
    "        #x[ground_node] = tg.nn.global_mean_pool(x[~ground_node], subgraph_batch_index)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"Send message with edge attributes\"\"\"\n",
    "        input = [x_i, x_j, edge_attr]\n",
    "        input = [val for val in input if val is not None]\n",
    "        input = torch.cat(input, dim=-1)\n",
    "        message = self.message_net(input)\n",
    "\n",
    "        if self.edge_inference:\n",
    "            message = message * self.edge_inferrer(message)\n",
    "        return message\n",
    "\n",
    "    def update(self, message, x):\n",
    "        \"\"\"Update node\"\"\"\n",
    "        input = torch.cat((x, message), dim=-1)\n",
    "        update = self.update_net(input)\n",
    "        return update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class MP(tg.nn.MessagePassing):\n",
    "    \"\"\"Message Passing Neural Network Layer\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_features,\n",
    "        edge_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "        aggr=\"add\",\n",
    "        act=nn.ReLU,\n",
    "        edge_inference=False,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr)\n",
    "        self.edge_inference = edge_inference\n",
    "        self.message_net = nn.Sequential(\n",
    "            nn.Linear(2 * node_features + edge_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Linear(node_features + hidden_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, out_features),\n",
    "        )\n",
    "\n",
    "        if edge_inference:\n",
    "            self.edge_inferrer = nn.Sequential(\n",
    "                nn.Linear(hidden_features, 1), nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        \"\"\"Propagate\"\"\"\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        # global pool over nodes whose ground node is false\n",
    "        #x[ground_node] = tg.nn.global_mean_pool(x[~ground_node], subgraph_batch_index)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"Send message with edge attributes\"\"\"\n",
    "        input = [x_i, x_j, edge_attr]\n",
    "        input = [val for val in input if val is not None]\n",
    "        input = torch.cat(input, dim=-1)\n",
    "        message = self.message_net(input)\n",
    "\n",
    "        if self.edge_inference:\n",
    "            message = message * self.edge_inferrer(message)\n",
    "        return message\n",
    "\n",
    "    def update(self, message, x):\n",
    "        \"\"\"Update node\"\"\"\n",
    "        input = torch.cat((x, message), dim=-1)\n",
    "        update = self.update_net(input)\n",
    "        return update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class FractalNet(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.fractal_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.fractal_mps.append(FractalMP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        x = self.embedding(x)\n",
    "        for i in range(self.depth):\n",
    "            x = self.fractal_mps[i](x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index, ground_node, subgraph_batch_index, edge_attr)\n",
    "        x = self.output(x)\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class FractalNetSeparated(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.ground_mps = nn.ModuleList()\n",
    "        self.ground_to_sub_mps = nn.ModuleList()\n",
    "        self.sub_mps = nn.ModuleList()\n",
    "        self.sub_to_ground_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.ground_to_sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_to_ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        x = self.embedding(x)\n",
    "        for i in range(self.depth):\n",
    "            x = self.ground_mps[i](x, edge_index, edge_attr)\n",
    "            x = self.ground_to_sub_mps[i](x, node_subnode_index, edge_attr)\n",
    "            x = self.sub_mps[i](x, subgraph_edge_index, edge_attr)\n",
    "            x = self.sub_to_ground_mps[i](x, subnode_node_index, edge_attr)\n",
    "        x = self.output(x)\n",
    "        print('before global mean pool', x.shape)\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        print('after global mean pool', x.shape)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.mps= nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx, edge_attr=None):\n",
    "        x = self.embedding(x)\n",
    "        for i in range(self.depth):\n",
    "            x = self.mps[i](x, edge_index, edge_attr)\n",
    "        x = self.output(x)\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        x = tg.nn.global_mean_pool(x, batch_idx)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "LABEL_INDEX = 7\n",
    "def get_qm9(data_dir, device=\"cuda\"):\n",
    "    \"\"\"Download the QM9 dataset from pytorch geometric. Put it onto the device. Split it up into train / validation / test.\n",
    "    Args:\n",
    "        data_dir: the directory to store the data.\n",
    "        device: put the data onto this device.\n",
    "    Returns:\n",
    "        train dataset, validation dataset, test dataset.\n",
    "    \"\"\"\n",
    "    dataset = QM9(data_dir)\n",
    "\n",
    "    # Permute the dataset\n",
    "    try:\n",
    "        permu = torch.load(\"permute.pt\")\n",
    "        dataset = dataset[permu]\n",
    "    except FileNotFoundError:\n",
    "        warn(\"Using non-standard permutation since permute.pt does not exist.\")\n",
    "        dataset, _ = dataset.shuffle(return_perm=True)\n",
    "\n",
    "    # z score / standard score targets to mean = 0 and std = 1.\n",
    "    mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "    std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "    dataset.data.y = (dataset.data.y - mean) / std\n",
    "    mean, std = mean[:, LABEL_INDEX].item(), std[:, LABEL_INDEX].item()\n",
    "\n",
    "    # Move the data to the device (it should fit on lisa gpus)\n",
    "    dataset.data = dataset.data.to(device)\n",
    "\n",
    "    len_train = 100_000\n",
    "    len_val = 10_000\n",
    "\n",
    "    train = dataset[:len_train]\n",
    "    valid = dataset[len_train : len_train + len_val]\n",
    "    test = dataset[len_train + len_val :]\n",
    "\n",
    "    assert len(dataset) == len(train) + len(valid) + len(test)\n",
    "\n",
    "    return train, valid, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "sample_graph = Subgraph(sample_data).convert_to_subgraph()\n",
    "node_features = sample_graph.x.shape[1]\n",
    "edge_features = 0\n",
    "hidden_features = 64\n",
    "out_features = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TRAINING A REGULAR FRACTAL NET ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b2345eba1c4f>:18: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-e925b25f3723>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mcriterion\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMSELoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# create a dataloader for qm9\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mdataset\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0m_\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0mget_qm9\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"data/qm9\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;31m# take a subset of the dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-10-b2345eba1c4f>\u001B[0m in \u001B[0;36mget_qm9\u001B[0;34m(data_dir, device)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0;31m# Move the data to the device (it should fit on lisa gpus)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m     \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[0mlen_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m100_000\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/data.py\u001B[0m in \u001B[0;36mto\u001B[0;34m(self, device, non_blocking, *args)\u001B[0m\n\u001B[1;32m    214\u001B[0m         r\"\"\"Performs tensor device conversion, either for all attributes or\n\u001B[1;32m    215\u001B[0m         only the ones given in :obj:`*args`.\"\"\"\n\u001B[0;32m--> 216\u001B[0;31m         return self.apply(\n\u001B[0m\u001B[1;32m    217\u001B[0m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/data.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, *args)\u001B[0m\n\u001B[1;32m    197\u001B[0m         the ones given in :obj:`*args`.\"\"\"\n\u001B[1;32m    198\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mstore\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstores\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 199\u001B[0;31m             \u001B[0mstore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    200\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, *args)\u001B[0m\n\u001B[1;32m    146\u001B[0m         the ones given in :obj:`*args`.\"\"\"\n\u001B[1;32m    147\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 148\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrecursive_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    149\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001B[0m in \u001B[0;36mrecursive_apply\u001B[0;34m(data, func)\u001B[0m\n\u001B[1;32m    502\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecursive_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    503\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSequence\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 504\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mrecursive_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    505\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMapping\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mrecursive_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    502\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecursive_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    503\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSequence\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 504\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mrecursive_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    505\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMapping\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mrecursive_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001B[0m in \u001B[0;36mrecursive_apply\u001B[0;34m(data, func)\u001B[0m\n\u001B[1;32m    497\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    498\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 499\u001B[0;31m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPackedSequence\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    500\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_fields'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# namedtuple\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# create a fractal net and train it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FractalNet(node_features, edge_features, hidden_features, out_features, depth=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "# create a dataloader for qm9\n",
    "dataset , _ ,_  = get_qm9(\"data/qm9\", device=device)\n",
    "# take a subset of the dataset\n",
    "dataset = dataset[:1000]\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        data = Subgraph(data).convert_to_subgraph().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target = data.y[:, LABEL_INDEX]\n",
    "        out = model(data.x, data.edge_index, data.subgraph_edge_index, data.node_subnode_index, data.subnode_node_index,data.ground_node, data.subgraph_batch_index, data.batch)\n",
    "        loss = criterion(out.mean(), target.mean())\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # show loss on tqdm\n",
    "        #tqdm.tqdm.write(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss/len(loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TRAINING A UNROLLED FRACTAL NET ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b2345eba1c4f>:18: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n"
     ]
    }
   ],
   "source": [
    "# create a fractal net and train it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FractalNetSeparated(node_features, edge_features, hidden_features, out_features, depth=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "# create a dataloader for qm9\n",
    "dataset , _ ,_  = get_qm9(\"data/qm9\", device=device)\n",
    "# take a subset of the dataset\n",
    "dataset = dataset[:1000]\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5620d1f5b7304c7da40cf70f773c9bc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1307]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.7190], device='cuda:0')\n",
      "before global mean pool torch.Size([600, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1359]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.1326], device='cuda:0')\n",
      "before global mean pool torch.Size([552, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1348]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.3664], device='cuda:0')\n",
      "before global mean pool torch.Size([240, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1264]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([2.5660], device='cuda:0')\n",
      "before global mean pool torch.Size([420, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1337]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.6191], device='cuda:0')\n",
      "before global mean pool torch.Size([462, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1382]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.5954], device='cuda:0')\n",
      "before global mean pool torch.Size([462, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1424]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.3350], device='cuda:0')\n",
      "before global mean pool torch.Size([240, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1375]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.7788], device='cuda:0')\n",
      "before global mean pool torch.Size([182, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1378]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.1212], device='cuda:0')\n",
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1488]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.6266], device='cuda:0')\n",
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1523]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-1.2378], device='cuda:0')\n",
      "before global mean pool torch.Size([272, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1478]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.5826], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1498]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([1.5813], device='cuda:0')\n",
      "before global mean pool torch.Size([240, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1469]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-1.0825], device='cuda:0')\n",
      "before global mean pool torch.Size([210, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1450]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.8066], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1516]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.7064], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1506]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([1.1566], device='cuda:0')\n",
      "before global mean pool torch.Size([306, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1499]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.1794], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1517]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.2231], device='cuda:0')\n",
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1535]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.3045], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1514]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.3194], device='cuda:0')\n",
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1527]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.6247], device='cuda:0')\n",
      "before global mean pool torch.Size([506, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1578]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([1.0952], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1545]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([3.4585], device='cuda:0')\n",
      "before global mean pool torch.Size([240, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1569]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.2767], device='cuda:0')\n",
      "before global mean pool torch.Size([272, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1661]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.6796], device='cuda:0')\n",
      "before global mean pool torch.Size([182, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1641]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-1.1461], device='cuda:0')\n",
      "before global mean pool torch.Size([272, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1739]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([1.7059], device='cuda:0')\n",
      "before global mean pool torch.Size([156, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1682]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([1.2599], device='cuda:0')\n",
      "before global mean pool torch.Size([272, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1860]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.2517], device='cuda:0')\n",
      "before global mean pool torch.Size([462, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2077]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.3359], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2015]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.7081], device='cuda:0')\n",
      "before global mean pool torch.Size([462, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2124]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.3370], device='cuda:0')\n",
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2044]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-1.2364], device='cuda:0')\n",
      "before global mean pool torch.Size([420, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2023]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([2.4816], device='cuda:0')\n",
      "before global mean pool torch.Size([420, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2043]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([1.5492], device='cuda:0')\n",
      "before global mean pool torch.Size([210, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1898]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-1.4821], device='cuda:0')\n",
      "before global mean pool torch.Size([420, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2113]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.1923], device='cuda:0')\n",
      "before global mean pool torch.Size([182, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1881]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-1.0510], device='cuda:0')\n",
      "before global mean pool torch.Size([306, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2004]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-2.1375], device='cuda:0')\n",
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.2001]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.3063], device='cuda:0')\n",
      "before global mean pool torch.Size([342, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1897]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.7085], device='cuda:0')\n",
      "before global mean pool torch.Size([600, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1971]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.1312], device='cuda:0')\n",
      "before global mean pool torch.Size([272, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1699]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.6785], device='cuda:0')\n",
      "before global mean pool torch.Size([380, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1691]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.6241], device='cuda:0')\n",
      "before global mean pool torch.Size([210, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1540]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.6503], device='cuda:0')\n",
      "before global mean pool torch.Size([156, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1456]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([1.7637], device='cuda:0')\n",
      "before global mean pool torch.Size([420, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1551]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.7383], device='cuda:0')\n",
      "before global mean pool torch.Size([240, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1438]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.2777], device='cuda:0')\n",
      "before global mean pool torch.Size([420, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1469]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([0.1942], device='cuda:0')\n",
      "before global mean pool torch.Size([306, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1404]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  tensor([-0.2737], device='cuda:0')\n",
      "before global mean pool torch.Size([462, 1])\n",
      "after global mean pool torch.Size([1, 1])\n",
      "out is  tensor([[0.1415]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "target is  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-4e4584f9dacb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0medge_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubgraph_edge_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnode_subnode_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubnode_node_index\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mground_node\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubgraph_batch_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'out is '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'target is '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36m__repr__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    303\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__repr__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m         \u001B[0;31m# All strings are unicode in Python 3.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 305\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tensor_str\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    307\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/_tensor_str.py\u001B[0m in \u001B[0;36m_str\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    433\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 434\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_str_intern\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/_tensor_str.py\u001B[0m in \u001B[0;36m_str_intern\u001B[0;34m(inp)\u001B[0m\n\u001B[1;32m    407\u001B[0m                     \u001B[0mtensor_str\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_tensor_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_dense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    408\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 409\u001B[0;31m                     \u001B[0mtensor_str\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_tensor_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    410\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayout\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrided\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/_tensor_str.py\u001B[0m in \u001B[0;36m_tensor_str\u001B[0;34m(self, indent)\u001B[0m\n\u001B[1;32m    263\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m         \u001B[0mformatter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_Formatter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_summarized_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0msummarize\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 265\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_tensor_str_with_formatter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msummarize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformatter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    266\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_add_suffixes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor_str\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuffixes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_newline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/_tensor_str.py\u001B[0m in \u001B[0;36m_tensor_str_with_formatter\u001B[0;34m(self, indent, summarize, formatter1, formatter2)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_vector_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msummarize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformatter1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformatter2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0msummarize\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mPRINT_OPTS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0medgeitems\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/_tensor_str.py\u001B[0m in \u001B[0;36m_vector_str\u001B[0;34m(self, indent, summarize, formatter1, formatter2)\u001B[0m\n\u001B[1;32m    200\u001B[0m                 [_val_formatter(val) for val in self[-PRINT_OPTS.edgeitems:].tolist()])\n\u001B[1;32m    201\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0m_val_formatter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mval\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    203\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0mdata_lines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mi\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0melements_per_line\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0melements_per_line\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        data = Subgraph(data).convert_to_subgraph().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target = data.y[:, LABEL_INDEX]\n",
    "        out = model(data.x, data.edge_index, data.subgraph_edge_index, data.node_subnode_index, data.subnode_node_index,data.ground_node, data.subgraph_batch_index, data.batch)\n",
    "        print('out is ', out)\n",
    "        print('target is ', target)\n",
    "        loss = criterion(out.mean(), target.mean())\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # show loss on tqdm\n",
    "        #tqdm.tqdm.write(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss/len(loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TRAINING A NORMAL NET ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a fractal net and train it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(node_features, edge_features, hidden_features, out_features, depth=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "# create a dataloader for qm9\n",
    "dataset , _ ,_  = get_qm9(\"data/qm9\", device=device)\n",
    "# take a subset of the dataset\n",
    "dataset = dataset[:1000]\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target = data.y[:, LABEL_INDEX]\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out.mean(), target.mean())\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # show loss on tqdm\n",
    "        #tqdm.tqdm.write(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss/len(loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}