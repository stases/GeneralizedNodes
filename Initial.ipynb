{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import tqdm.notebook as tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "# import QM9 dataset\n",
    "from torch_geometric.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
      "Extracting /home/tin/data/QM9/raw/qm9_v3.zip\n",
      "Processing...\n",
      "Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load some data from QM9\n",
    "data = QM9('~/data/QM9') # this will download the dataset if it is not already present\n",
    "sample_data = data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Subgraph:\n",
    "    def __init__(self, graph, depth=1):\n",
    "        self.num_nodes = graph.x.shape[0]\n",
    "        self.subgraph = graph.clone()\n",
    "\n",
    "    def convert_to_subgraph(self):\n",
    "        self.add_subnode_features()\n",
    "        self.add_node_flags()\n",
    "        self.add_subnode_edges()\n",
    "        self.add_node_subnode_edges()\n",
    "        self.add_subnode_node_edges()\n",
    "        self.add_subgraph_batch_index()\n",
    "        return self.subgraph\n",
    "\n",
    "    def add_subnode_features(self):\n",
    "        self.subgraph.x = self.subgraph.x.repeat(self.num_nodes+1,1)\n",
    "        self.total_num_nodes = self.subgraph.x.shape[0]\n",
    "\n",
    "    def add_node_flags(self):\n",
    "        if hasattr(self.subgraph, 'x'):\n",
    "            self.subgraph.ground_node = torch.arange(self.subgraph.x.shape[0]) < self.num_nodes\n",
    "        else:\n",
    "            print('No node features found. Please add node features first.')\n",
    "\n",
    "    def add_subnode_edges(self):\n",
    "        self.subgraph.subgraph_edge_index = self.subgraph.edge_index + self.num_nodes\n",
    "        for subg in range(self.num_nodes):\n",
    "            self.subgraph.subgraph_edge_index = torch.cat([self.subgraph.subgraph_edge_index, self.subgraph.edge_index + (subg+1)*self.num_nodes], dim=1)\n",
    "\n",
    "    def add_node_subnode_edges(self):\n",
    "        self.subgraph.node_subnode_index = torch.stack([torch.arange(self.num_nodes).repeat_interleave(self.num_nodes), torch.arange(self.num_nodes, self.total_num_nodes)], dim=0)\n",
    "\n",
    "    def add_subnode_node_edges(self):\n",
    "        self.subgraph.subnode_node_index = torch.stack([torch.arange(self.num_nodes, self.total_num_nodes), torch.arange(self.num_nodes).repeat_interleave(self.num_nodes)], dim=0)\n",
    "\n",
    "    def add_subgraph_batch_index(self):\n",
    "        self.subgraph.subgraph_batch_index = torch.arange(self.num_nodes).repeat_interleave(self.num_nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class FractalMP(tg.nn.MessagePassing):\n",
    "    \"\"\"Message Passing Neural Network Layer\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_features,\n",
    "        edge_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "        aggr=\"add\",\n",
    "        act=nn.ReLU,\n",
    "        edge_inference=False,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr)\n",
    "        self.edge_inference = edge_inference\n",
    "        self.message_net = nn.Sequential(\n",
    "            nn.Linear(2 * node_features + edge_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Linear(node_features + hidden_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, out_features),\n",
    "        )\n",
    "\n",
    "        if edge_inference:\n",
    "            self.edge_inferrer = nn.Sequential(\n",
    "                nn.Linear(hidden_features, 1), nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, edge_attr=None):\n",
    "        \"\"\"Propagate\"\"\"\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(node_subnode_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(subgraph_edge_index, x=x, edge_attr=edge_attr)\n",
    "        x = self.propagate(subnode_node_index, x=x, edge_attr=edge_attr)\n",
    "        # global pool over nodes whose ground node is false\n",
    "        #x[ground_node] = tg.nn.global_mean_pool(x[~ground_node], subgraph_batch_index)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"Send message with edge attributes\"\"\"\n",
    "        input = [x_i, x_j, edge_attr]\n",
    "        input = [val for val in input if val is not None]\n",
    "        input = torch.cat(input, dim=-1)\n",
    "        message = self.message_net(input)\n",
    "\n",
    "        if self.edge_inference:\n",
    "            message = message * self.edge_inferrer(message)\n",
    "        return message\n",
    "\n",
    "    def update(self, message, x):\n",
    "        \"\"\"Update node\"\"\"\n",
    "        input = torch.cat((x, message), dim=-1)\n",
    "        update = self.update_net(input)\n",
    "        return update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class MP(tg.nn.MessagePassing):\n",
    "    \"\"\"Message Passing Neural Network Layer\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_features,\n",
    "        edge_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "        aggr=\"add\",\n",
    "        act=nn.ReLU,\n",
    "        edge_inference=False,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr)\n",
    "        self.edge_inference = edge_inference\n",
    "        self.message_net = nn.Sequential(\n",
    "            nn.Linear(2 * node_features + edge_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Linear(node_features + hidden_features, hidden_features),\n",
    "            act(),\n",
    "            nn.Linear(hidden_features, out_features),\n",
    "        )\n",
    "\n",
    "        if edge_inference:\n",
    "            self.edge_inferrer = nn.Sequential(\n",
    "                nn.Linear(hidden_features, 1), nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        \"\"\"Propagate\"\"\"\n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        # global pool over nodes whose ground node is false\n",
    "        #x[ground_node] = tg.nn.global_mean_pool(x[~ground_node], subgraph_batch_index)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"Send message with edge attributes\"\"\"\n",
    "        input = [x_i, x_j, edge_attr]\n",
    "        input = [val for val in input if val is not None]\n",
    "        input = torch.cat(input, dim=-1)\n",
    "        message = self.message_net(input)\n",
    "\n",
    "        if self.edge_inference:\n",
    "            message = message * self.edge_inferrer(message)\n",
    "        return message\n",
    "\n",
    "    def update(self, message, x):\n",
    "        \"\"\"Update node\"\"\"\n",
    "        input = torch.cat((x, message), dim=-1)\n",
    "        update = self.update_net(input)\n",
    "        return update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class FractalNet(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.fractal_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.fractal_mps.append(FractalMP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        x = self.embedding(x)\n",
    "        for i in range(self.depth):\n",
    "            x = self.fractal_mps[i](x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index, ground_node, subgraph_batch_index, edge_attr)\n",
    "        x = self.output(x)\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.mps= nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx, edge_attr=None):\n",
    "        x = self.embedding(x)\n",
    "        for i in range(self.depth):\n",
    "            x = self.mps[i](x, edge_index, edge_attr)\n",
    "        x = self.output(x)\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        x = tg.nn.global_mean_pool(x, batch_idx)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "LABEL_INDEX = 7\n",
    "def get_qm9(data_dir, device=\"cuda\"):\n",
    "    \"\"\"Download the QM9 dataset from pytorch geometric. Put it onto the device. Split it up into train / validation / test.\n",
    "    Args:\n",
    "        data_dir: the directory to store the data.\n",
    "        device: put the data onto this device.\n",
    "    Returns:\n",
    "        train dataset, validation dataset, test dataset.\n",
    "    \"\"\"\n",
    "    dataset = QM9(data_dir)\n",
    "\n",
    "    # Permute the dataset\n",
    "    try:\n",
    "        permu = torch.load(\"permute.pt\")\n",
    "        dataset = dataset[permu]\n",
    "    except FileNotFoundError:\n",
    "        warn(\"Using non-standard permutation since permute.pt does not exist.\")\n",
    "        dataset, _ = dataset.shuffle(return_perm=True)\n",
    "\n",
    "    # z score / standard score targets to mean = 0 and std = 1.\n",
    "    mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "    std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "    dataset.data.y = (dataset.data.y - mean) / std\n",
    "    mean, std = mean[:, LABEL_INDEX].item(), std[:, LABEL_INDEX].item()\n",
    "\n",
    "    # Move the data to the device (it should fit on lisa gpus)\n",
    "    dataset.data = dataset.data.to(device)\n",
    "\n",
    "    len_train = 100_000\n",
    "    len_val = 10_000\n",
    "\n",
    "    train = dataset[:len_train]\n",
    "    valid = dataset[len_train : len_train + len_val]\n",
    "    test = dataset[len_train + len_val :]\n",
    "\n",
    "    assert len(dataset) == len(train) + len(valid) + len(test)\n",
    "\n",
    "    return train, valid, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "sample_graph = Subgraph(sample_data).convert_to_subgraph()\n",
    "node_features = sample_graph.x.shape[1]\n",
    "edge_features = 0\n",
    "hidden_features = 64\n",
    "out_features = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-b2345eba1c4f>:18: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n"
     ]
    }
   ],
   "source": [
    "# create a fractal net and train it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FractalNet(node_features, edge_features, hidden_features, out_features, depth=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "# create a dataloader for qm9\n",
    "dataset , _ ,_  = get_qm9(\"data/qm9\", device=device)\n",
    "# take a subset of the dataset\n",
    "dataset = dataset[:1000]\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "241806f0b35c4b3b800746577ca6c36d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.073101335724861\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "239fc16aaece4e9da12aac4792c54e51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.0620371259624244\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6b1c585f2b7474aa6d8368f9865f20a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.0683593535865157\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d113c00ede24cb094b5838abd85d15e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 1.0583966165635128\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a1c1d3b69564647a28f00bd3d01c688"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 1.0579530307153218\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14bcba0c8b9f4c2bb3d6e78d19f3f98e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 1.05041362085742\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "189c130c68a441059cf2fbaeb5840f66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 1.0541219793174592\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1451c9447ff44ad9375cc775a6379b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 1.0531785792173254\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9bfedc178de4a69b332d45c2f6cbd76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 1.0824002637266836\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b96d3a2c6c964a72bd4c04959c814d9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-38-255766bfd0eb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mavg_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSubgraph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_subgraph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/tqdm/notebook.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtqdm_notebook\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__iter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m                 \u001B[0;31m# return super(tqdm...) will not catch exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/tqdm/std.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1193\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1194\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1195\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1196\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1197\u001B[0m                 \u001B[0;31m# Update and possibly print the progressbar.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    528\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    529\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    568\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    569\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 570\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    571\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    572\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollate_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0melem\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBaseData\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m             return Batch.from_data_list(batch, self.follow_batch,\n\u001B[0m\u001B[1;32m     20\u001B[0m                                         self.exclude_keys)\n\u001B[1;32m     21\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0melem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/batch.py\u001B[0m in \u001B[0;36mfrom_data_list\u001B[0;34m(cls, data_list, follow_batch, exclude_keys)\u001B[0m\n\u001B[1;32m     66\u001B[0m         Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\n\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 68\u001B[0;31m         batch, slice_dict, inc_dict = collate(\n\u001B[0m\u001B[1;32m     69\u001B[0m             \u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0mdata_list\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/Geometric/lib/python3.8/site-packages/torch_geometric/data/collate.py\u001B[0m in \u001B[0;36mcollate\u001B[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m def collate(\n\u001B[0m\u001B[1;32m     14\u001B[0m     \u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0mdata_list\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mBaseData\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        data = Subgraph(data).convert_to_subgraph().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target = data.y[:, LABEL_INDEX]\n",
    "        out = model(data.x, data.edge_index, data.subgraph_edge_index, data.node_subnode_index, data.subnode_node_index,data.ground_node, data.subgraph_batch_index, data.batch)\n",
    "        loss = criterion(out.mean(), target.mean())\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # show loss on tqdm\n",
    "        #tqdm.tqdm.write(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss/len(loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-b2345eba1c4f>:18: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n"
     ]
    }
   ],
   "source": [
    "# create a fractal net and train it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(node_features, edge_features, hidden_features, out_features, depth=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "# create a dataloader for qm9\n",
    "dataset , _ ,_  = get_qm9(\"data/qm9\", device=device)\n",
    "# take a subset of the dataset\n",
    "dataset = dataset[:1000]\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f440a026c8141d59bb3c58d6c6be9df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.9170646348850532\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a841e5746235410aa8987758a2ad9fe4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5146421588427995\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2669580683da46958172bf59a9ec4bea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.44401671928236974\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02d2fa060df44727add1c796ef110ff1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.4253722649442109\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3655d83ed17b42f59a7cc5204ae9a79d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.4185420137951988\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeecf07875a44e07a19b8921e54bf8f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.4126145760485356\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af4fcd83875b4b7197251acb9929c652"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.39480555454569755\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23a315ccd17045ad8eafffd1a35e98d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.4031608042938587\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b51c7bcea4740ff84830344e8ea6486"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.4067556886764195\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c900c869d94492d9632263d0add33aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.4092115295977925\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    avg_loss = 0\n",
    "    for data in tqdm.tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target = data.y[:, LABEL_INDEX]\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out.mean(), target.mean())\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # show loss on tqdm\n",
    "        #tqdm.tqdm.write(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss/len(loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}