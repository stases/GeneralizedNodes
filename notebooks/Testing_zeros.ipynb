{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#from networks import FractalNet, FractalNetShared, Net, GNN_no_rel, GNN\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#from subgraph import Graph_to_Subgraph\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#from train import train_model, get_qm9\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_model, get_qm9\n",
      "File \u001B[0;32m~/Documents/Github/FractalMessagePassing/train.py:59\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m#####################\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m#####################\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m#  Config loading    #\u001B[39;00m\n\u001B[1;32m     58\u001B[0m config_file \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 59\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     60\u001B[0m     config \u001B[38;5;241m=\u001B[39m yaml\u001B[38;5;241m.\u001B[39msafe_load(f)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m#####################\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m#####################\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m#  Config parsing    #\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "#from networks import FractalNet, FractalNetShared, Net, GNN_no_rel, GNN\n",
    "#from subgraph import Graph_to_Subgraph\n",
    "#from train import train_model, get_qm9\n",
    "from train import train_model, get_qm9\n",
    "#from subgraph import Subgraph\n",
    "#from layers import MP"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T10:21:27.744925748Z",
     "start_time": "2023-05-03T10:21:27.682414515Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.0+cu121.html\r\n",
      "Processing /home/tin/.cache/pip/wheels/ff/6c/d6/f131acff9176ff91cb7ce97ddcd7170182c99533bf31c86a1d/torch_geometric-2.3.1-py3-none-any.whl\r\n",
      "Collecting torch-sparse\r\n",
      "  Using cached torch_sparse-0.6.17.tar.gz (209 kB)\r\n",
      "Processing /home/tin/.cache/pip/wheels/6e/7d/ef/cc482ff35ea019f4e2285e42174449007bb177576eb4f5fae9/torch_scatter-2.1.1-cp38-cp38-linux_x86_64.whl\r\n",
      "Collecting torch-cluster\r\n",
      "  Downloading torch_cluster-1.6.1.tar.gz (53 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 53 kB 3.4 MB/s eta 0:00:011\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (2.11.3)\r\n",
      "Requirement already satisfied: requests in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (2.30.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (1.0.2)\r\n",
      "Requirement already satisfied: pyparsing in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (2.4.7)\r\n",
      "Requirement already satisfied: numpy in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (1.21.5)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (5.9.5)\r\n",
      "Requirement already satisfied: tqdm in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (4.63.0)\r\n",
      "Requirement already satisfied: scipy in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from torch-geometric) (1.7.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from jinja2->torch-geometric) (1.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from requests->torch-geometric) (3.3)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from requests->torch-geometric) (2.0.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from requests->torch-geometric) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from requests->torch-geometric) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tin/miniconda3/envs/Geometric/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (2.2.0)\r\n",
      "Building wheels for collected packages: torch-sparse, torch-cluster\r\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for torch-sparse: filename=torch_sparse-0.6.17-cp38-cp38-linux_x86_64.whl size=2659061 sha256=6c47b0cf8130e0fa8d3dec6240fcb54ac0b81f31a6dbb04479f86266cef8f359\r\n",
      "  Stored in directory: /home/tin/.cache/pip/wheels/22/b4/54/ca8f8938b70218d75f3b96bb1c2126d16521fb5996191b4efe\r\n",
      "  Building wheel for torch-cluster (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for torch-cluster: filename=torch_cluster-1.6.1-cp38-cp38-linux_x86_64.whl size=1985627 sha256=bfc7635fcf69d89ae2417247be03c923a3b2ca8b6a965b7901e96a3eff9dc992\r\n",
      "  Stored in directory: /home/tin/.cache/pip/wheels/f3/12/75/d433fa44b5efa713e5eb9c995dc62e8c0114ba8df8bfc5980f\r\n",
      "Successfully built torch-sparse torch-cluster\r\n",
      "Installing collected packages: torch-geometric, torch-sparse, torch-scatter, torch-cluster\r\n",
      "Successfully installed torch-cluster-1.6.1 torch-geometric-2.3.1 torch-scatter-2.1.1 torch-sparse-0.6.17\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric \\\n",
    "  torch-sparse \\\n",
    "  torch-scatter \\\n",
    "  torch-cluster \\\n",
    "  -f https://pytorch-geometric.com/whl/torch-2.0.0+cu121.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# get a random 8 by 12 tensor\n",
    "x = torch.rand(8, 12)\n",
    "Z_ONE = None\n",
    "y = x[:, :Z_ONE]\n",
    "print(y.shape)\n",
    "# are x and y equal\n",
    "print(torch.equal(x, y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T13:11:30.162646006Z",
     "start_time": "2023-05-03T13:11:30.156975675Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/Documents/Github/FractalMessagePassing/train.py:23: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n",
      "/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = get_qm9('./data')\n",
    "# get a sample data\n",
    "data = dataset[0]\n",
    "sample_data = data[0].to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:44:20.885210Z",
     "end_time": "2023-04-12T14:44:22.863021Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# find the smallest data and set it as sample_data\n",
    "for data_point in data:\n",
    "    if data_point.num_nodes < sample_data.num_nodes:\n",
    "        # stop if the number of num nodes is less than 5\n",
    "        if data_point.num_nodes < 5:\n",
    "            break\n",
    "        sample_data = data_point.to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:45:01.545362Z",
     "end_time": "2023-04-12T14:45:07.545903Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[6, 11], edge_index=[2, 12], edge_attr=[12, 4], y=[1, 19], pos=[6, 3], idx=[1], name='gdb_174', z=[6])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "subgraph_example = Subgraph(sample_data, mode='transformer_3').convert_to_subgraph()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:45:42.183970Z",
     "end_time": "2023-04-12T14:45:42.227770Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  torch.Size([20, 8])\n",
      "Number of edges:  torch.Size([2, 8])\n",
      "Subedge index torch.Size([2, 45])\n",
      "Maximum value in subedge index:  tensor(19)\n"
     ]
    }
   ],
   "source": [
    "# print all the statistics\n",
    "print('Number of nodes: ', subgraph_example.x.shape)\n",
    "print('Number of edges: ', subgraph_example.edge_index.shape)\n",
    "print('Subedge index', subgraph_example.subgraph_edge_index.shape)\n",
    "# print the maximum value in the subedge index\n",
    "print('Maximum value in subedge index: ', torch.max(subgraph_example.subgraph_edge_index))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:45:43.124493Z",
     "end_time": "2023-04-12T14:45:43.137328Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10,\n",
      "         11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16,\n",
      "         17, 17, 17, 18, 18, 18, 19, 19, 19],\n",
      "        [ 5,  6,  7,  5,  6,  7,  5,  6,  7,  8,  9, 10,  8,  9, 10,  8,  9, 10,\n",
      "         11, 12, 13, 11, 12, 13, 11, 12, 13, 14, 15, 16, 14, 15, 16, 14, 15, 16,\n",
      "         17, 18, 19, 17, 18, 19, 17, 18, 19]])\n"
     ]
    }
   ],
   "source": [
    "# print the subgraph edge index\n",
    "print(subgraph_example.subgraph_edge_index)\n",
    "sample_data = subgraph_example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:57:03.949647Z",
     "end_time": "2023-04-12T14:57:03.992741Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from layers import FractalMP, MP\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool\n",
    "import os\n",
    "from utils import catch_lone_sender\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "class FractalNet(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1, pool=\"mean\", add_residual_skip=False):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.pool = pool\n",
    "        self.add_residual_skip = add_residual_skip\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.ground_mps = nn.ModuleList()\n",
    "        self.ground_to_sub_mps = nn.ModuleList()\n",
    "        self.sub_mps = nn.ModuleList()\n",
    "        self.sub_to_ground_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.ground_to_sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_to_ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        num_nodes = x.shape[0]\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            if self.add_residual_skip:\n",
    "                x_0 = x\n",
    "\n",
    "            update_mask = catch_lone_sender(edge_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            # check whether x contains zeros\n",
    "            # print states of the not ground nodes\n",
    "\n",
    "            x_subnode_state = x[~ground_node]\n",
    "\n",
    "            x = self.ground_mps[i](x, edge_index, edge_attr)\n",
    "            # print sattes of the not ground nodes after mp\n",
    "            # check whether the x subnode state is changed by comparing\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "            #x[~update_mask] = x_backup\n",
    "            #TODO: Check the order of edge indices; directed in which direction? subnode to node or vice versa\n",
    "\n",
    "            #update_mask = catch_lone_sender(node_subnode_index, num_nodes)\n",
    "            #x_backup = x[~update_mask]\n",
    "\n",
    "            update_mask = catch_lone_sender(node_subnode_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x_subnode_state = x[~ground_node]\n",
    "            x = self.ground_to_sub_mps[i](x, node_subnode_index, edge_attr)\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "\n",
    "            x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subgraph_edge_index, num_nodes)\n",
    "            #x_backup = x[~update_mask]\n",
    "            #\n",
    "            x_subnode_state = x[~ground_node]\n",
    "            x = self.sub_mps[i](x, subgraph_edge_index, edge_attr)\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "\n",
    "            x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subnode_node_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            #\n",
    "            x_subnode_state = x[~ground_node]\n",
    "            x = self.sub_to_ground_mps[i](x, subnode_node_index, edge_attr)\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "            #x[~update_mask] = x_backup\n",
    "\n",
    "            if self.add_residual_skip:\n",
    "                x = x + x_0\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        if self.pool == \"mean\":\n",
    "            x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"add\":\n",
    "            x = tg.nn.global_add_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"max\":\n",
    "            x = tg.nn.global_max_pool(x[ground_node], batch_idx)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T15:16:23.154507Z",
     "end_time": "2023-04-12T15:16:23.159290Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FractalNet(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1, pool=\"mean\", add_residual_skip=False, masking=False):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.pool = pool\n",
    "        self.add_residual_skip = add_residual_skip\n",
    "        self.masking = masking\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.ground_mps = nn.ModuleList()\n",
    "        self.ground_to_sub_mps = nn.ModuleList()\n",
    "        self.sub_mps = nn.ModuleList()\n",
    "        self.sub_to_ground_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.ground_to_sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_to_ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        num_nodes = x.shape[0]\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            if self.add_residual_skip:\n",
    "                x_0 = x\n",
    "\n",
    "            update_mask = catch_lone_sender(edge_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.ground_mps[i](x, edge_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "            #TODO: Check the order of edge indices; directed in which direction? subnode to node or vice versa\n",
    "\n",
    "            update_mask = catch_lone_sender(node_subnode_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.ground_to_sub_mps[i](x, node_subnode_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subgraph_edge_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.sub_mps[i](x, subgraph_edge_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subnode_node_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.sub_to_ground_mps[i](x, subnode_node_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "\n",
    "            if self.add_residual_skip:\n",
    "                x = x + x_0\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        if self.pool == \"mean\":\n",
    "            x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"add\":\n",
    "            x = tg.nn.global_add_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"max\":\n",
    "            x = tg.nn.global_max_pool(x[ground_node], batch_idx)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states of the not ground nodes after mp:  True\n",
      "states of the not ground nodes after mp:  False\n",
      "states of the not ground nodes after mp:  False\n",
      "states of the not ground nodes after mp:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.0665],\n        [-0.1118],\n        [ 0.0665],\n        [ 0.0665],\n        [ 0.0665],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755],\n        [ 0.0332],\n        [-0.1200],\n        [-0.1756],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the sample datapoint through the fractal network\n",
    "# the idea is to check whether backup does what was intented (i.e. not changing the state of the not ground nodes when they are not participating in the MP. This is due to update net updating all nodes)\n",
    "fractal_net = FractalNet(sample_data.x.shape[1],0, 64, 1, depth=1, pool=None, add_residual_skip=True)\n",
    "fractal_net.forward(sample_data.x, sample_data.edge_index, sample_data.subgraph_edge_index, sample_data.node_subnode_index, sample_data.subnode_node_index, sample_data.ground_node, sample_data.subgraph_batch_index, None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T15:16:23.531591Z",
     "end_time": "2023-04-12T15:16:23.576282Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T15:11:34.279724Z",
     "end_time": "2023-04-12T15:11:34.280089Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}