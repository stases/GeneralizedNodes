{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from networks import FractalNet, FractalNetShared, Net, GNN_no_rel, GNN\n",
    "from subgraph import Graph_to_Subgraph\n",
    "from train import train_model, get_qm9\n",
    "from train import train_model, get_qm9\n",
    "from subgraph import Subgraph\n",
    "from layers import MP"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:44:19.629800Z",
     "end_time": "2023-04-12T14:44:19.679621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/Documents/Github/FractalMessagePassing/train.py:23: UserWarning: Using non-standard permutation since permute.pt does not exist.\n",
      "  warn(\"Using non-standard permutation since permute.pt does not exist.\")\n",
      "/home/tin/anaconda3/envs/AudioSeparation/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = get_qm9('./data')\n",
    "# get a sample data\n",
    "data = dataset[0]\n",
    "sample_data = data[0].to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:44:20.885210Z",
     "end_time": "2023-04-12T14:44:22.863021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# find the smallest data and set it as sample_data\n",
    "for data_point in data:\n",
    "    if data_point.num_nodes < sample_data.num_nodes:\n",
    "        # stop if the number of num nodes is less than 5\n",
    "        if data_point.num_nodes < 5:\n",
    "            break\n",
    "        sample_data = data_point.to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:45:01.545362Z",
     "end_time": "2023-04-12T14:45:07.545903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[6, 11], edge_index=[2, 12], edge_attr=[12, 4], y=[1, 19], pos=[6, 3], idx=[1], name='gdb_174', z=[6])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "subgraph_example = Subgraph(sample_data, mode='transformer_3').convert_to_subgraph()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:45:42.183970Z",
     "end_time": "2023-04-12T14:45:42.227770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  torch.Size([20, 8])\n",
      "Number of edges:  torch.Size([2, 8])\n",
      "Subedge index torch.Size([2, 45])\n",
      "Maximum value in subedge index:  tensor(19)\n"
     ]
    }
   ],
   "source": [
    "# print all the statistics\n",
    "print('Number of nodes: ', subgraph_example.x.shape)\n",
    "print('Number of edges: ', subgraph_example.edge_index.shape)\n",
    "print('Subedge index', subgraph_example.subgraph_edge_index.shape)\n",
    "# print the maximum value in the subedge index\n",
    "print('Maximum value in subedge index: ', torch.max(subgraph_example.subgraph_edge_index))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:45:43.124493Z",
     "end_time": "2023-04-12T14:45:43.137328Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10,\n",
      "         11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16,\n",
      "         17, 17, 17, 18, 18, 18, 19, 19, 19],\n",
      "        [ 5,  6,  7,  5,  6,  7,  5,  6,  7,  8,  9, 10,  8,  9, 10,  8,  9, 10,\n",
      "         11, 12, 13, 11, 12, 13, 11, 12, 13, 14, 15, 16, 14, 15, 16, 14, 15, 16,\n",
      "         17, 18, 19, 17, 18, 19, 17, 18, 19]])\n"
     ]
    }
   ],
   "source": [
    "# print the subgraph edge index\n",
    "print(subgraph_example.subgraph_edge_index)\n",
    "sample_data = subgraph_example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:57:03.949647Z",
     "end_time": "2023-04-12T14:57:03.992741Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from layers import FractalMP, MP\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool\n",
    "import os\n",
    "from utils import catch_lone_sender\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "class FractalNet(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1, pool=\"mean\", add_residual_skip=False):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.pool = pool\n",
    "        self.add_residual_skip = add_residual_skip\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.ground_mps = nn.ModuleList()\n",
    "        self.ground_to_sub_mps = nn.ModuleList()\n",
    "        self.sub_mps = nn.ModuleList()\n",
    "        self.sub_to_ground_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.ground_to_sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_to_ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        num_nodes = x.shape[0]\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            if self.add_residual_skip:\n",
    "                x_0 = x\n",
    "\n",
    "            update_mask = catch_lone_sender(edge_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            # check whether x contains zeros\n",
    "            # print states of the not ground nodes\n",
    "\n",
    "            x_subnode_state = x[~ground_node]\n",
    "\n",
    "            x = self.ground_mps[i](x, edge_index, edge_attr)\n",
    "            # print sattes of the not ground nodes after mp\n",
    "            # check whether the x subnode state is changed by comparing\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "            #x[~update_mask] = x_backup\n",
    "            #TODO: Check the order of edge indices; directed in which direction? subnode to node or vice versa\n",
    "\n",
    "            #update_mask = catch_lone_sender(node_subnode_index, num_nodes)\n",
    "            #x_backup = x[~update_mask]\n",
    "\n",
    "            update_mask = catch_lone_sender(node_subnode_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x_subnode_state = x[~ground_node]\n",
    "            x = self.ground_to_sub_mps[i](x, node_subnode_index, edge_attr)\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "\n",
    "            x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subgraph_edge_index, num_nodes)\n",
    "            #x_backup = x[~update_mask]\n",
    "            #\n",
    "            x_subnode_state = x[~ground_node]\n",
    "            x = self.sub_mps[i](x, subgraph_edge_index, edge_attr)\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "\n",
    "            x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subnode_node_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            #\n",
    "            x_subnode_state = x[~ground_node]\n",
    "            x = self.sub_to_ground_mps[i](x, subnode_node_index, edge_attr)\n",
    "            x[~update_mask] = x_backup\n",
    "            x_subnode_state_after = x[~ground_node]\n",
    "            print('states of the not ground nodes after mp: ', torch.equal(x_subnode_state, x_subnode_state_after))\n",
    "            #x[~update_mask] = x_backup\n",
    "\n",
    "            if self.add_residual_skip:\n",
    "                x = x + x_0\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        if self.pool == \"mean\":\n",
    "            x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"add\":\n",
    "            x = tg.nn.global_add_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"max\":\n",
    "            x = tg.nn.global_max_pool(x[ground_node], batch_idx)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T15:16:23.154507Z",
     "end_time": "2023-04-12T15:16:23.159290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FractalNet(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_features, out_features, depth=1, pool=\"mean\", add_residual_skip=False, masking=False):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.pool = pool\n",
    "        self.add_residual_skip = add_residual_skip\n",
    "        self.masking = masking\n",
    "        self.embedding = nn.Linear(node_features, hidden_features)\n",
    "        self.ground_mps = nn.ModuleList()\n",
    "        self.ground_to_sub_mps = nn.ModuleList()\n",
    "        self.sub_mps = nn.ModuleList()\n",
    "        self.sub_to_ground_mps = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.ground_to_sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "            self.sub_to_ground_mps.append(MP(hidden_features, edge_features, hidden_features, hidden_features))\n",
    "        self.output = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, subgraph_edge_index, node_subnode_index, subnode_node_index ,ground_node, subgraph_batch_index, batch_idx, edge_attr=None):\n",
    "        num_nodes = x.shape[0]\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            if self.add_residual_skip:\n",
    "                x_0 = x\n",
    "\n",
    "            update_mask = catch_lone_sender(edge_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.ground_mps[i](x, edge_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "            #TODO: Check the order of edge indices; directed in which direction? subnode to node or vice versa\n",
    "\n",
    "            update_mask = catch_lone_sender(node_subnode_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.ground_to_sub_mps[i](x, node_subnode_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subgraph_edge_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.sub_mps[i](x, subgraph_edge_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "\n",
    "            update_mask = catch_lone_sender(subnode_node_index, num_nodes)\n",
    "            x_backup = x[~update_mask]\n",
    "            x = self.sub_to_ground_mps[i](x, subnode_node_index, edge_attr)\n",
    "            if self.masking:\n",
    "                x[~update_mask] = x_backup\n",
    "\n",
    "            if self.add_residual_skip:\n",
    "                x = x + x_0\n",
    "        # global pooling over nodes whose ground node is true\n",
    "        if self.pool == \"mean\":\n",
    "            x = tg.nn.global_mean_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"add\":\n",
    "            x = tg.nn.global_add_pool(x[ground_node], batch_idx)\n",
    "        elif self.pool == \"max\":\n",
    "            x = tg.nn.global_max_pool(x[ground_node], batch_idx)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states of the not ground nodes after mp:  True\n",
      "states of the not ground nodes after mp:  False\n",
      "states of the not ground nodes after mp:  False\n",
      "states of the not ground nodes after mp:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.0665],\n        [-0.1118],\n        [ 0.0665],\n        [ 0.0665],\n        [ 0.0665],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755],\n        [ 0.0332],\n        [-0.1200],\n        [-0.1756],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755],\n        [ 0.0333],\n        [-0.1199],\n        [-0.1755]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the sample datapoint through the fractal network\n",
    "# the idea is to check whether backup does what was intented (i.e. not changing the state of the not ground nodes when they are not participating in the MP. This is due to update net updating all nodes)\n",
    "fractal_net = FractalNet(sample_data.x.shape[1],0, 64, 1, depth=1, pool=None, add_residual_skip=True)\n",
    "fractal_net.forward(sample_data.x, sample_data.edge_index, sample_data.subgraph_edge_index, sample_data.node_subnode_index, sample_data.subnode_node_index, sample_data.ground_node, sample_data.subgraph_batch_index, None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T15:16:23.531591Z",
     "end_time": "2023-04-12T15:16:23.576282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T15:11:34.279724Z",
     "end_time": "2023-04-12T15:11:34.280089Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
