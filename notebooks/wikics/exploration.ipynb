{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from itertools import chain\n",
    "from typing import Callable, List, Optional\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import wikics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "notebook_path = os.getcwd()  # Get the current working directory\n",
    "notebook_folder = os.path.dirname(notebook_path)  # Get the parent directory of the notebook\n",
    "root = os.path.abspath(os.path.join(notebook_folder, '..', '..', 'data', 'WikiCS'))  # Construct the root path\n",
    "sys.path.append('../..')  # Add the path to the script folder\n",
    "\n",
    "from utils.transforms import Graph_to_Subgraph\n",
    "dataset = wikics.WikiCS(root=root, transform=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([False, False, False,  ..., False, False,  True])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_idx = 5\n",
    "dataset[0].train_mask[:, mask_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "all_data = dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[11701, 300], edge_index=[2, 431726], y=[11701], train_mask=[11701, 20], val_mask=[11701, 20], test_mask=[11701], stopping_mask=[11701, 20])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 2679, 2: 2153, 3: 1933, 9: 1424, 7: 865, 5: 780, 1: 667, 8: 492, 6: 413, 0: 295})\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the histogram distributio of the labels\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "labels = all_data.y.numpy()\n",
    "#labels = labels[labels != -1]\n",
    "counter=collections.Counter(labels)\n",
    "print(counter)\n",
    "plt.hist(labels, bins=range(0, 10))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(300, 64)\n",
      "  (conv2): GCNConv(64, 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size, hidden_size)  # GCN layer\n",
    "        self.conv2 = GCNConv(hidden_size, output_size)  # GCN layer\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)  # Apply GCN layer 1\n",
    "        x = torch.relu(x)  # Apply ReLU activation\n",
    "        x = self.conv2(x, edge_index)  # Apply GCN layer 2\n",
    "        return x\n",
    "\n",
    "# Define the sizes of input, hidden, and output features\n",
    "input_size = 300\n",
    "hidden_size = 64\n",
    "output_size = 10\n",
    "\n",
    "# Create an instance of the GCN model\n",
    "gcn = GCN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Print the network architecture\n",
    "print(gcn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Additional function to compute accuracy\n",
    "def calculate_accuracy(output, labels, mask):\n",
    "    _, predicted = torch.max(output[mask], dim=1)\n",
    "    correct = (predicted == labels[mask]).sum().item()\n",
    "    return correct / mask.sum().item()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/Fractal/lib/python3.9/site-packages/torch_geometric/datasets/wikics.py:38: UserWarning: The WikiCS dataset now returns an undirected graph by default. Please explicitly specify 'is_undirected=False' to restore the old behavior.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Training Loss: 2.3078, Training Accuracy: 0.2224\n",
      "Epoch 1/30, Validation Loss: 2.0575, Validation Accuracy: 0.4641\n",
      "--------------------------------------------------\n",
      "Epoch 2/30, Training Loss: 2.0473, Training Accuracy: 0.4707\n",
      "Epoch 2/30, Validation Loss: 1.9617, Validation Accuracy: 0.3804\n",
      "--------------------------------------------------\n",
      "Epoch 3/30, Training Loss: 1.9356, Training Accuracy: 0.3759\n",
      "Epoch 3/30, Validation Loss: 1.8725, Validation Accuracy: 0.4454\n",
      "--------------------------------------------------\n",
      "Epoch 4/30, Training Loss: 1.8322, Training Accuracy: 0.4793\n",
      "Epoch 4/30, Validation Loss: 1.7355, Validation Accuracy: 0.5743\n",
      "--------------------------------------------------\n",
      "Epoch 5/30, Training Loss: 1.6862, Training Accuracy: 0.5914\n",
      "Epoch 5/30, Validation Loss: 1.6345, Validation Accuracy: 0.6015\n",
      "--------------------------------------------------\n",
      "Epoch 6/30, Training Loss: 1.5793, Training Accuracy: 0.5983\n",
      "Epoch 6/30, Validation Loss: 1.5356, Validation Accuracy: 0.5856\n",
      "--------------------------------------------------\n",
      "Epoch 7/30, Training Loss: 1.4777, Training Accuracy: 0.5897\n",
      "Epoch 7/30, Validation Loss: 1.4397, Validation Accuracy: 0.5681\n",
      "--------------------------------------------------\n",
      "Epoch 8/30, Training Loss: 1.3825, Training Accuracy: 0.5724\n",
      "Epoch 8/30, Validation Loss: 1.3523, Validation Accuracy: 0.5947\n",
      "--------------------------------------------------\n",
      "Epoch 9/30, Training Loss: 1.2959, Training Accuracy: 0.5931\n",
      "Epoch 9/30, Validation Loss: 1.2797, Validation Accuracy: 0.6071\n",
      "--------------------------------------------------\n",
      "Epoch 10/30, Training Loss: 1.2206, Training Accuracy: 0.6086\n",
      "Epoch 10/30, Validation Loss: 1.2158, Validation Accuracy: 0.6303\n",
      "--------------------------------------------------\n",
      "Epoch 11/30, Training Loss: 1.1506, Training Accuracy: 0.6310\n",
      "Epoch 11/30, Validation Loss: 1.1555, Validation Accuracy: 0.6574\n",
      "--------------------------------------------------\n",
      "Epoch 12/30, Training Loss: 1.0840, Training Accuracy: 0.6638\n",
      "Epoch 12/30, Validation Loss: 1.1082, Validation Accuracy: 0.6738\n",
      "--------------------------------------------------\n",
      "Epoch 13/30, Training Loss: 1.0320, Training Accuracy: 0.6948\n",
      "Epoch 13/30, Validation Loss: 1.0626, Validation Accuracy: 0.6919\n",
      "--------------------------------------------------\n",
      "Epoch 14/30, Training Loss: 0.9838, Training Accuracy: 0.7034\n",
      "Epoch 14/30, Validation Loss: 1.0149, Validation Accuracy: 0.7077\n",
      "--------------------------------------------------\n",
      "Epoch 15/30, Training Loss: 0.9352, Training Accuracy: 0.7172\n",
      "Epoch 15/30, Validation Loss: 0.9763, Validation Accuracy: 0.7157\n",
      "--------------------------------------------------\n",
      "Epoch 16/30, Training Loss: 0.8951, Training Accuracy: 0.7293\n",
      "Epoch 16/30, Validation Loss: 0.9465, Validation Accuracy: 0.7196\n",
      "--------------------------------------------------\n",
      "Epoch 17/30, Training Loss: 0.8624, Training Accuracy: 0.7397\n",
      "Epoch 17/30, Validation Loss: 0.9201, Validation Accuracy: 0.7292\n",
      "--------------------------------------------------\n",
      "Epoch 18/30, Training Loss: 0.8317, Training Accuracy: 0.7517\n",
      "Epoch 18/30, Validation Loss: 0.8966, Validation Accuracy: 0.7428\n",
      "--------------------------------------------------\n",
      "Epoch 19/30, Training Loss: 0.8021, Training Accuracy: 0.7586\n",
      "Epoch 19/30, Validation Loss: 0.8793, Validation Accuracy: 0.7524\n",
      "--------------------------------------------------\n",
      "Epoch 20/30, Training Loss: 0.7762, Training Accuracy: 0.7621\n",
      "Epoch 20/30, Validation Loss: 0.8666, Validation Accuracy: 0.7575\n",
      "--------------------------------------------------\n",
      "Epoch 21/30, Training Loss: 0.7540, Training Accuracy: 0.7621\n",
      "Epoch 21/30, Validation Loss: 0.8513, Validation Accuracy: 0.7575\n",
      "--------------------------------------------------\n",
      "Epoch 22/30, Training Loss: 0.7298, Training Accuracy: 0.7724\n",
      "Epoch 22/30, Validation Loss: 0.8365, Validation Accuracy: 0.7648\n",
      "--------------------------------------------------\n",
      "Epoch 23/30, Training Loss: 0.7065, Training Accuracy: 0.7862\n",
      "Epoch 23/30, Validation Loss: 0.8286, Validation Accuracy: 0.7694\n",
      "--------------------------------------------------\n",
      "Epoch 24/30, Training Loss: 0.6896, Training Accuracy: 0.7879\n",
      "Epoch 24/30, Validation Loss: 0.8221, Validation Accuracy: 0.7722\n",
      "--------------------------------------------------\n",
      "Epoch 25/30, Training Loss: 0.6733, Training Accuracy: 0.7983\n",
      "Epoch 25/30, Validation Loss: 0.8147, Validation Accuracy: 0.7733\n",
      "--------------------------------------------------\n",
      "Epoch 26/30, Training Loss: 0.6555, Training Accuracy: 0.8034\n",
      "Epoch 26/30, Validation Loss: 0.8095, Validation Accuracy: 0.7750\n",
      "--------------------------------------------------\n",
      "Epoch 27/30, Training Loss: 0.6400, Training Accuracy: 0.8069\n",
      "Epoch 27/30, Validation Loss: 0.8046, Validation Accuracy: 0.7795\n",
      "--------------------------------------------------\n",
      "Epoch 28/30, Training Loss: 0.6253, Training Accuracy: 0.8121\n",
      "Epoch 28/30, Validation Loss: 0.7981, Validation Accuracy: 0.7846\n",
      "--------------------------------------------------\n",
      "Epoch 29/30, Training Loss: 0.6100, Training Accuracy: 0.8155\n",
      "Epoch 29/30, Validation Loss: 0.7921, Validation Accuracy: 0.7858\n",
      "--------------------------------------------------\n",
      "Epoch 30/30, Training Loss: 0.5962, Training Accuracy: 0.8103\n",
      "Epoch 30/30, Validation Loss: 0.7866, Validation Accuracy: 0.7931\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training loop for 10 epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# Specify the mask indices for train and validation\n",
    "mask_idx_train = 0\n",
    "mask_idx_val = 1\n",
    "train_mask = all_data.train_mask[:, mask_idx_train]\n",
    "val_mask = all_data.val_mask[:, mask_idx_val]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gcn.parameters(), lr=0.02)\n",
    "\n",
    "# Define your validation dataset similar to the training dataset\n",
    "dataset = wikics.WikiCS(root=root)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    gcn.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Training phase\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        x, y, edge_index = batch.x, batch.y, batch.edge_index\n",
    "        output = gcn(x, edge_index)\n",
    "        loss = criterion(output[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_acc = calculate_accuracy(output, y, train_mask)\n",
    "\n",
    "    # Print the average loss for the current epoch\n",
    "    average_loss = epoch_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {average_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    gcn.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for batch in loader:\n",
    "            x, y, edge_index = batch.x, batch.y, batch.edge_index\n",
    "            output = gcn(x, edge_index)\n",
    "            val_loss += criterion(output[val_mask], y[val_mask]).item()\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_acc = calculate_accuracy(output, y, val_mask)\n",
    "\n",
    "        average_val_loss = val_loss / len(loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # print a straight line to separate epochs\n",
    "        print(\"--------------------------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "class Graph_to_Subgraph(BaseTransform):\n",
    "    def __init__(self, mode='fractal', depth=1, fully_connect=False):\n",
    "        self.mode = mode\n",
    "        self.depth = depth\n",
    "        self.fully_connect = fully_connect\n",
    "    def __call__(self, data):\n",
    "        subgraph = Subgraph(data, mode=self.mode, depth=self.depth, fully_connect=self.fully_connect)\n",
    "        return subgraph.convert_to_subgraph()\n",
    "\n",
    "class Subgraph:\n",
    "    def __init__(self, graph, mode='fractal', fully_connect=False, depth=1):\n",
    "        self.device = graph.x.device\n",
    "        self.num_nodes = graph.x.shape[0]\n",
    "        self.subgraph = graph.clone().to(self.device)\n",
    "        self.mode = mode\n",
    "        self.fully_connect = fully_connect\n",
    "        #TODO: not have this hardcoded\n",
    "        self.crop_onehot = None # 5 is specific for QM9\n",
    "        if 'transformer' in mode:\n",
    "            self.mode = 'transformer'\n",
    "            # split a string by underscore, for example transformer_3 into transformer and 3\n",
    "            self.transformer_size = int(mode.split('_')[1])\n",
    "\n",
    "    def convert_to_subgraph(self):\n",
    "        if self.fully_connect:\n",
    "            self.add_fully_connected_edges()\n",
    "        self.add_subnode_features()\n",
    "        self.add_subnode_forces()\n",
    "        self.add_subatom_index()\n",
    "        self.add_subnode_position()\n",
    "        self.add_node_flags()\n",
    "        self.add_subnode_edges()\n",
    "        self.add_node_subnode_edges()\n",
    "        self.add_subnode_node_edges()\n",
    "        self.add_subgraph_batch_index()\n",
    "        return self.subgraph\n",
    "\n",
    "    def add_fully_connected_edges(self):\n",
    "        # This uses fully_connect_existing_nodes from tools.py, as we want to get a fully connecte graph in a given range\n",
    "        # We don't want to connect accidentally nodes that are not in the subgraph, and vice-versa\n",
    "        self.subgraph.edge_index = fully_connect_existing_nodes(edge_index=self.subgraph.edge_index).to(self.device)\n",
    "        #self.subgraph.subgraph_edge_index = fully_connect_existing_nodes(edge_index=self.subgraph.subgraph_edge_index).to(self.device)\n",
    "\n",
    "    def add_subnode_features(self):\n",
    "        if self.crop_onehot:\n",
    "            # take only the self.crop_onehot first features\n",
    "            self.subgraph.x = self.subgraph.x[:, :self.crop_onehot]\n",
    "        if self.mode == 'fractal':\n",
    "            self.subgraph.x = self.subgraph.x.repeat(self.num_nodes+1,1)\n",
    "        self.num_features = self.subgraph.x.shape[1]\n",
    "        self.total_num_nodes = self.subgraph.x.shape[0]\n",
    "\n",
    "        if self.mode == 'transformer':\n",
    "            self.subgraph.x = torch.cat([self.subgraph.x, torch.zeros(self.num_nodes, self.transformer_size).to(self.device)], dim=1)\n",
    "            # create nodes for the transformer, where each node is one hot encoded to the transformer_size\n",
    "            transformer_nodes = torch.eye(self.transformer_size)\n",
    "            # now append zeros of the transformer_size at dimension 1\n",
    "            transformer_nodes = torch.cat([torch.zeros(self.transformer_size, self.num_features), transformer_nodes], dim=1).to(self.device)\n",
    "            # add transformer nodes to the subgraph for every node\n",
    "            self.subgraph.x = torch.cat([self.subgraph.x, transformer_nodes.repeat(self.num_nodes,1)], dim=0)\n",
    "        # Total number of nodes after adding the subgraph structure\n",
    "        self.total_num_nodes = self.subgraph.x.shape[0]\n",
    "\n",
    "    def add_subnode_position(self):\n",
    "        if self.subgraph.pos is not None:\n",
    "            print('Adding subnode positions')\n",
    "\n",
    "            num_dimensions = self.subgraph.pos.shape[1]\n",
    "            if self.mode == 'fractal':\n",
    "                self.subgraph.pos = self.subgraph.pos.repeat(self.num_nodes+1,1)\n",
    "            # In the case of the transformer, the position has no interpretable meaning so we don't se it.\n",
    "            elif self.mode == 'transformer':\n",
    "                # Fill up subgraph.pos for the new nodes with the positions of the node they belong to\n",
    "                self.subgraph.pos = torch.cat([self.subgraph.pos, self.subgraph.pos.repeat_interleave(self.transformer_size, dim=0)], dim=0)\n",
    "\n",
    "                #self.subgraph.pos = torch.cat([self.subgraph.pos, torch.zeros(self.total_num_nodes-self.num_nodes, num_dimensions).to(self.device)], dim=0)\n",
    "                # asser that subgraph pos[0] is equal to total num of nodes\n",
    "                assert self.subgraph.pos.shape[0] == self.total_num_nodes\n",
    "\n",
    "\n",
    "    def add_subnode_forces(self):\n",
    "        if hasattr(self.subgraph, 'force'):\n",
    "            if self.mode == 'fractal':\n",
    "                self.subgraph.force = self.subgraph.force.repeat(self.num_nodes+1,1)\n",
    "            elif self.mode == 'transformer':\n",
    "                # do same as for positions\n",
    "                self.subgraph.force = torch.cat([self.subgraph.force, torch.zeros(self.total_num_nodes-self.num_nodes, 3).to(self.device)], dim=0)\n",
    "                assert self.subgraph.force.shape[0] == self.total_num_nodes\n",
    "\n",
    "    def add_node_flags(self):\n",
    "        if hasattr(self.subgraph, 'x'):\n",
    "            self.subgraph.ground_node = torch.arange(self.subgraph.x.shape[0]) < self.num_nodes\n",
    "        else:\n",
    "            raise ValueError('No node features found. Please add node features first.')\n",
    "\n",
    "    def add_subnode_edges(self):\n",
    "        if self.mode == 'fractal':\n",
    "            self.subgraph.subgraph_edge_index = self.subgraph.edge_index + self.num_nodes\n",
    "            for subg in range(self.num_nodes-1):\n",
    "                #TODO: Check if this is correct\n",
    "                self.subgraph.subgraph_edge_index = torch.cat([self.subgraph.subgraph_edge_index,\n",
    "                                                               self.subgraph.edge_index + self.num_nodes + (subg+1)*self.num_nodes],\n",
    "                                                              dim=1)\n",
    "        elif self.mode == 'transformer':\n",
    "            # create a fully connected edge index for the transformer of size transformer_size\n",
    "            transformer_edge_index = torch.stack([torch.arange(self.transformer_size).repeat_interleave(self.transformer_size),\n",
    "                                                  torch.arange(self.transformer_size).repeat(self.transformer_size)],\n",
    "                                                 dim=0).to(self.device)\n",
    "            self.subgraph.subgraph_edge_index = transformer_edge_index + self.num_nodes\n",
    "            for subg in range(self.num_nodes-1):\n",
    "                #TODO: Check if this is correct\n",
    "                self.subgraph.subgraph_edge_index = torch.cat([self.subgraph.subgraph_edge_index,\n",
    "                                                               transformer_edge_index  + self.num_nodes + (subg+1)*self.transformer_size],\n",
    "                                                              dim=1).to(self.device)\n",
    "    def add_node_subnode_edges(self):\n",
    "        if self.mode == 'fractal':\n",
    "            self.subgraph.node_subnode_index = torch.stack([torch.arange(self.num_nodes).repeat_interleave(self.num_nodes),\n",
    "                                                            torch.arange(self.num_nodes, self.total_num_nodes)],\n",
    "                                                           dim=0).to(self.device)\n",
    "        elif self.mode == 'transformer':\n",
    "            self.subgraph.node_subnode_index = torch.stack([torch.arange(self.num_nodes).repeat_interleave(self.transformer_size),\n",
    "                                                            torch.arange(self.num_nodes, self.total_num_nodes)],\n",
    "                                                           dim=0).to(self.device)\n",
    "\n",
    "    def add_subnode_node_edges(self):\n",
    "        if self.mode == 'fractal':\n",
    "            self.subgraph.subnode_node_index = torch.stack([torch.arange(self.num_nodes, self.total_num_nodes), torch.arange(self.num_nodes).repeat_interleave(self.num_nodes)], dim=0)\n",
    "        elif self.mode == 'transformer':\n",
    "            self.subgraph.subnode_node_index = torch.stack([torch.arange(self.num_nodes, self.total_num_nodes),\n",
    "                                                            torch.arange(self.num_nodes).repeat_interleave(self.transformer_size)],\n",
    "                                                           dim=0).to(self.device)\n",
    "\n",
    "    def add_subgraph_batch_index(self):\n",
    "        if self.mode == 'fractal':\n",
    "            self.subgraph.subgraph_batch_index = torch.arange(self.num_nodes).repeat_interleave(self.num_nodes)\n",
    "        elif self.mode == 'transformer':\n",
    "            self.subgraph.subgraph_batch_index = torch.arange(self.num_nodes).repeat_interleave(self.transformer_size)\n",
    "\n",
    "    def add_subatom_index(self):\n",
    "        if self.mode == 'fractal':\n",
    "            self.subgraph.subatom_index = torch.arange(self.num_nodes).repeat(self.num_nodes+1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[70206, 305], edge_index=[2, 431726], y=[11701], train_mask=[11701, 20], val_mask=[11701, 20], test_mask=[11701], stopping_mask=[11701, 20], ground_node=[70206], subgraph_edge_index=[2, 292525], node_subnode_index=[2, 58505], subnode_node_index=[2, 58505], subgraph_batch_index=[58505])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = Graph_to_Subgraph(mode='transformer_5')\n",
    "dataset = wikics.WikiCS(root=root, transform=transforms)\n",
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer_GCN(\n",
      "  (ground_conv1): GCNConv(305, 64)\n",
      "  (ground_conv2): GCNConv(64, 64)\n",
      "  (gts_conv1): GCNConv(64, 64)\n",
      "  (gts_conv2): GCNConv(64, 64)\n",
      "  (sub_conv1): GCNConv(64, 64)\n",
      "  (sub_conv2): GCNConv(64, 64)\n",
      "  (stg_conv1): GCNConv(64, 64)\n",
      "  (stg_conv2): GCNConv(64, 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.functional as F\n",
    "# Define the GCN model\n",
    "class Transformer_GCN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Transformer_GCN, self).__init__()\n",
    "        self.mask = True\n",
    "        self.ground_conv1 = GCNConv(input_size, hidden_size)  # GCN layer\n",
    "        self.ground_conv2 = GCNConv(hidden_size, hidden_size)  # GCN layer\n",
    "        self.gts_conv1 = GCNConv(hidden_size, hidden_size)  # GCN layer\n",
    "        self.gts_conv2 = GCNConv(hidden_size, hidden_size)  # GCN layer\n",
    "        self.sub_conv1 = GCNConv(hidden_size, hidden_size)  # GCN layer\n",
    "        self.sub_conv2 = GCNConv(hidden_size, hidden_size)  # GCN layer\n",
    "        self.stg_conv1 = GCNConv(hidden_size, hidden_size)  # GCN layer\n",
    "        self.stg_conv2 = GCNConv(hidden_size, output_size)  # GCN layer\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x, edge_index, _ = batch.x, batch.edge_index, batch.batch\n",
    "        node_subnode_index = batch.node_subnode_index\n",
    "        subgraph_edge_index = batch.subgraph_edge_index\n",
    "        subnode_node_index = batch.subnode_node_index\n",
    "\n",
    "        x = self.ground_conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gts_conv1(x, node_subnode_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.sub_conv1(x, subgraph_edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.stg_conv1(x, subnode_node_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.ground_conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gts_conv2(x, node_subnode_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.sub_conv2(x, subgraph_edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.stg_conv2(x, subnode_node_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define the sizes of input, hidden, and output features\n",
    "input_size = 305\n",
    "hidden_size = 64\n",
    "output_size = 10\n",
    "\n",
    "# Create an instance of the GCN model\n",
    "gcn = Transformer_GCN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Print the network architecture\n",
    "print(gcn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 2.3143, Training Accuracy: 0.0241\n",
      "Epoch 1/100, Validation Loss: 2.2763, Validation Accuracy: 0.0786\n",
      "--------------------------------------------------\n",
      "Epoch 2/100, Training Loss: 2.2748, Training Accuracy: 0.0897\n",
      "Epoch 2/100, Validation Loss: 2.2305, Validation Accuracy: 0.1860\n",
      "--------------------------------------------------\n",
      "Epoch 3/100, Training Loss: 2.2268, Training Accuracy: 0.1862\n",
      "Epoch 3/100, Validation Loss: 2.1726, Validation Accuracy: 0.2109\n",
      "--------------------------------------------------\n",
      "Epoch 4/100, Training Loss: 2.1664, Training Accuracy: 0.2121\n",
      "Epoch 4/100, Validation Loss: 2.1167, Validation Accuracy: 0.1877\n",
      "--------------------------------------------------\n",
      "Epoch 5/100, Training Loss: 2.1052, Training Accuracy: 0.1931\n",
      "Epoch 5/100, Validation Loss: 2.0839, Validation Accuracy: 0.1854\n",
      "--------------------------------------------------\n",
      "Epoch 6/100, Training Loss: 2.0645, Training Accuracy: 0.1931\n",
      "Epoch 6/100, Validation Loss: 2.0542, Validation Accuracy: 0.3488\n",
      "--------------------------------------------------\n",
      "Epoch 7/100, Training Loss: 2.0278, Training Accuracy: 0.3638\n",
      "Epoch 7/100, Validation Loss: 2.0036, Validation Accuracy: 0.3578\n",
      "--------------------------------------------------\n",
      "Epoch 8/100, Training Loss: 1.9744, Training Accuracy: 0.3828\n",
      "Epoch 8/100, Validation Loss: 1.9538, Validation Accuracy: 0.3375\n",
      "--------------------------------------------------\n",
      "Epoch 9/100, Training Loss: 1.9249, Training Accuracy: 0.3638\n",
      "Epoch 9/100, Validation Loss: 1.9062, Validation Accuracy: 0.3386\n",
      "--------------------------------------------------\n",
      "Epoch 10/100, Training Loss: 1.8749, Training Accuracy: 0.3552\n",
      "Epoch 10/100, Validation Loss: 1.8670, Validation Accuracy: 0.3233\n",
      "--------------------------------------------------\n",
      "Epoch 11/100, Training Loss: 1.8300, Training Accuracy: 0.3517\n",
      "Epoch 11/100, Validation Loss: 1.8274, Validation Accuracy: 0.3256\n",
      "--------------------------------------------------\n",
      "Epoch 12/100, Training Loss: 1.7838, Training Accuracy: 0.3362\n",
      "Epoch 12/100, Validation Loss: 1.7979, Validation Accuracy: 0.3477\n",
      "--------------------------------------------------\n",
      "Epoch 13/100, Training Loss: 1.7450, Training Accuracy: 0.3448\n",
      "Epoch 13/100, Validation Loss: 1.7783, Validation Accuracy: 0.4059\n",
      "--------------------------------------------------\n",
      "Epoch 14/100, Training Loss: 1.7140, Training Accuracy: 0.3897\n",
      "Epoch 14/100, Validation Loss: 1.7599, Validation Accuracy: 0.4234\n",
      "--------------------------------------------------\n",
      "Epoch 15/100, Training Loss: 1.6870, Training Accuracy: 0.4259\n",
      "Epoch 15/100, Validation Loss: 1.7335, Validation Accuracy: 0.4375\n",
      "--------------------------------------------------\n",
      "Epoch 16/100, Training Loss: 1.6535, Training Accuracy: 0.4431\n",
      "Epoch 16/100, Validation Loss: 1.6996, Validation Accuracy: 0.4845\n",
      "--------------------------------------------------\n",
      "Epoch 17/100, Training Loss: 1.6159, Training Accuracy: 0.4983\n",
      "Epoch 17/100, Validation Loss: 1.6715, Validation Accuracy: 0.4743\n",
      "--------------------------------------------------\n",
      "Epoch 18/100, Training Loss: 1.5821, Training Accuracy: 0.4672\n",
      "Epoch 18/100, Validation Loss: 1.6485, Validation Accuracy: 0.5008\n",
      "--------------------------------------------------\n",
      "Epoch 19/100, Training Loss: 1.5586, Training Accuracy: 0.5034\n",
      "Epoch 19/100, Validation Loss: 1.6470, Validation Accuracy: 0.4715\n",
      "--------------------------------------------------\n",
      "Epoch 20/100, Training Loss: 1.5425, Training Accuracy: 0.4552\n",
      "Epoch 20/100, Validation Loss: 1.6073, Validation Accuracy: 0.4958\n",
      "--------------------------------------------------\n",
      "Epoch 21/100, Training Loss: 1.5098, Training Accuracy: 0.5121\n",
      "Epoch 21/100, Validation Loss: 1.5603, Validation Accuracy: 0.5229\n",
      "--------------------------------------------------\n",
      "Epoch 22/100, Training Loss: 1.4546, Training Accuracy: 0.5276\n",
      "Epoch 22/100, Validation Loss: 1.5819, Validation Accuracy: 0.5082\n",
      "--------------------------------------------------\n",
      "Epoch 23/100, Training Loss: 1.4607, Training Accuracy: 0.4828\n",
      "Epoch 23/100, Validation Loss: 1.5307, Validation Accuracy: 0.5308\n",
      "--------------------------------------------------\n",
      "Epoch 24/100, Training Loss: 1.4112, Training Accuracy: 0.5345\n",
      "Epoch 24/100, Validation Loss: 1.4999, Validation Accuracy: 0.5319\n",
      "--------------------------------------------------\n",
      "Epoch 25/100, Training Loss: 1.3718, Training Accuracy: 0.5379\n",
      "Epoch 25/100, Validation Loss: 1.4988, Validation Accuracy: 0.5444\n",
      "--------------------------------------------------\n",
      "Epoch 26/100, Training Loss: 1.3573, Training Accuracy: 0.5414\n",
      "Epoch 26/100, Validation Loss: 1.4349, Validation Accuracy: 0.5676\n",
      "--------------------------------------------------\n",
      "Epoch 27/100, Training Loss: 1.2923, Training Accuracy: 0.5690\n",
      "Epoch 27/100, Validation Loss: 1.4248, Validation Accuracy: 0.5585\n",
      "--------------------------------------------------\n",
      "Epoch 28/100, Training Loss: 1.2772, Training Accuracy: 0.5655\n",
      "Epoch 28/100, Validation Loss: 1.3771, Validation Accuracy: 0.5732\n",
      "--------------------------------------------------\n",
      "Epoch 29/100, Training Loss: 1.2195, Training Accuracy: 0.5793\n",
      "Epoch 29/100, Validation Loss: 1.3605, Validation Accuracy: 0.5924\n",
      "--------------------------------------------------\n",
      "Epoch 30/100, Training Loss: 1.1937, Training Accuracy: 0.5948\n",
      "Epoch 30/100, Validation Loss: 1.3311, Validation Accuracy: 0.5953\n",
      "--------------------------------------------------\n",
      "Epoch 31/100, Training Loss: 1.1595, Training Accuracy: 0.6052\n",
      "Epoch 31/100, Validation Loss: 1.2833, Validation Accuracy: 0.6190\n",
      "--------------------------------------------------\n",
      "Epoch 32/100, Training Loss: 1.1098, Training Accuracy: 0.6190\n",
      "Epoch 32/100, Validation Loss: 1.2778, Validation Accuracy: 0.6246\n",
      "--------------------------------------------------\n",
      "Epoch 33/100, Training Loss: 1.0946, Training Accuracy: 0.6328\n",
      "Epoch 33/100, Validation Loss: 1.2772, Validation Accuracy: 0.6224\n",
      "--------------------------------------------------\n",
      "Epoch 34/100, Training Loss: 1.0736, Training Accuracy: 0.6414\n",
      "Epoch 34/100, Validation Loss: 1.2231, Validation Accuracy: 0.6354\n",
      "--------------------------------------------------\n",
      "Epoch 35/100, Training Loss: 1.0210, Training Accuracy: 0.6414\n",
      "Epoch 35/100, Validation Loss: 1.2068, Validation Accuracy: 0.6399\n",
      "--------------------------------------------------\n",
      "Epoch 36/100, Training Loss: 0.9997, Training Accuracy: 0.6517\n",
      "Epoch 36/100, Validation Loss: 1.2266, Validation Accuracy: 0.6309\n",
      "--------------------------------------------------\n",
      "Epoch 37/100, Training Loss: 0.9985, Training Accuracy: 0.6552\n",
      "Epoch 37/100, Validation Loss: 1.1940, Validation Accuracy: 0.6444\n",
      "--------------------------------------------------\n",
      "Epoch 38/100, Training Loss: 0.9720, Training Accuracy: 0.6741\n",
      "Epoch 38/100, Validation Loss: 1.1622, Validation Accuracy: 0.6665\n",
      "--------------------------------------------------\n",
      "Epoch 39/100, Training Loss: 0.9309, Training Accuracy: 0.6914\n",
      "Epoch 39/100, Validation Loss: 1.1272, Validation Accuracy: 0.6761\n",
      "--------------------------------------------------\n",
      "Epoch 40/100, Training Loss: 0.8908, Training Accuracy: 0.7069\n",
      "Epoch 40/100, Validation Loss: 1.1281, Validation Accuracy: 0.6738\n",
      "--------------------------------------------------\n",
      "Epoch 41/100, Training Loss: 0.8909, Training Accuracy: 0.6845\n",
      "Epoch 41/100, Validation Loss: 1.1466, Validation Accuracy: 0.6642\n",
      "--------------------------------------------------\n",
      "Epoch 42/100, Training Loss: 0.8885, Training Accuracy: 0.7034\n",
      "Epoch 42/100, Validation Loss: 1.0927, Validation Accuracy: 0.6914\n",
      "--------------------------------------------------\n",
      "Epoch 43/100, Training Loss: 0.8542, Training Accuracy: 0.7052\n",
      "Epoch 43/100, Validation Loss: 1.1090, Validation Accuracy: 0.6880\n",
      "--------------------------------------------------\n",
      "Epoch 44/100, Training Loss: 0.8355, Training Accuracy: 0.7224\n",
      "Epoch 44/100, Validation Loss: 1.0989, Validation Accuracy: 0.6772\n",
      "--------------------------------------------------\n",
      "Epoch 45/100, Training Loss: 0.8277, Training Accuracy: 0.7276\n",
      "Epoch 45/100, Validation Loss: 1.0611, Validation Accuracy: 0.7027\n",
      "--------------------------------------------------\n",
      "Epoch 46/100, Training Loss: 0.7948, Training Accuracy: 0.7241\n",
      "Epoch 46/100, Validation Loss: 1.0844, Validation Accuracy: 0.6970\n",
      "--------------------------------------------------\n",
      "Epoch 47/100, Training Loss: 0.7919, Training Accuracy: 0.7431\n",
      "Epoch 47/100, Validation Loss: 1.0675, Validation Accuracy: 0.6930\n",
      "--------------------------------------------------\n",
      "Epoch 48/100, Training Loss: 0.7787, Training Accuracy: 0.7345\n",
      "Epoch 48/100, Validation Loss: 1.0476, Validation Accuracy: 0.7055\n",
      "--------------------------------------------------\n",
      "Epoch 49/100, Training Loss: 0.7460, Training Accuracy: 0.7466\n",
      "Epoch 49/100, Validation Loss: 1.0749, Validation Accuracy: 0.7049\n",
      "--------------------------------------------------\n",
      "Epoch 50/100, Training Loss: 0.7506, Training Accuracy: 0.7534\n",
      "Epoch 50/100, Validation Loss: 1.0504, Validation Accuracy: 0.7106\n",
      "--------------------------------------------------\n",
      "Epoch 51/100, Training Loss: 0.7342, Training Accuracy: 0.7500\n",
      "Epoch 51/100, Validation Loss: 1.0490, Validation Accuracy: 0.7117\n",
      "--------------------------------------------------\n",
      "Epoch 52/100, Training Loss: 0.7077, Training Accuracy: 0.7621\n",
      "Epoch 52/100, Validation Loss: 1.0540, Validation Accuracy: 0.7106\n",
      "--------------------------------------------------\n",
      "Epoch 53/100, Training Loss: 0.7038, Training Accuracy: 0.7672\n",
      "Epoch 53/100, Validation Loss: 1.0381, Validation Accuracy: 0.7157\n",
      "--------------------------------------------------\n",
      "Epoch 54/100, Training Loss: 0.6943, Training Accuracy: 0.7621\n",
      "Epoch 54/100, Validation Loss: 1.0488, Validation Accuracy: 0.7128\n",
      "--------------------------------------------------\n",
      "Epoch 55/100, Training Loss: 0.6813, Training Accuracy: 0.7759\n",
      "Epoch 55/100, Validation Loss: 1.0383, Validation Accuracy: 0.7292\n",
      "--------------------------------------------------\n",
      "Epoch 56/100, Training Loss: 0.6781, Training Accuracy: 0.7741\n",
      "Epoch 56/100, Validation Loss: 1.0485, Validation Accuracy: 0.7100\n",
      "--------------------------------------------------\n",
      "Epoch 57/100, Training Loss: 0.6749, Training Accuracy: 0.7793\n",
      "Epoch 57/100, Validation Loss: 1.0213, Validation Accuracy: 0.7349\n",
      "--------------------------------------------------\n",
      "Epoch 58/100, Training Loss: 0.6584, Training Accuracy: 0.7810\n",
      "Epoch 58/100, Validation Loss: 1.0355, Validation Accuracy: 0.7253\n",
      "--------------------------------------------------\n",
      "Epoch 59/100, Training Loss: 0.6507, Training Accuracy: 0.7793\n",
      "Epoch 59/100, Validation Loss: 1.0227, Validation Accuracy: 0.7281\n",
      "--------------------------------------------------\n",
      "Epoch 60/100, Training Loss: 0.6495, Training Accuracy: 0.7810\n",
      "Epoch 60/100, Validation Loss: 1.0384, Validation Accuracy: 0.7224\n",
      "--------------------------------------------------\n",
      "Epoch 61/100, Training Loss: 0.6516, Training Accuracy: 0.7897\n",
      "Epoch 61/100, Validation Loss: 1.0035, Validation Accuracy: 0.7337\n",
      "--------------------------------------------------\n",
      "Epoch 62/100, Training Loss: 0.5975, Training Accuracy: 0.7845\n",
      "Epoch 62/100, Validation Loss: 1.0494, Validation Accuracy: 0.7128\n",
      "--------------------------------------------------\n",
      "Epoch 63/100, Training Loss: 0.6345, Training Accuracy: 0.7828\n",
      "Epoch 63/100, Validation Loss: 1.0910, Validation Accuracy: 0.7157\n",
      "--------------------------------------------------\n",
      "Epoch 64/100, Training Loss: 0.6764, Training Accuracy: 0.7776\n",
      "Epoch 64/100, Validation Loss: 1.0323, Validation Accuracy: 0.7213\n",
      "--------------------------------------------------\n",
      "Epoch 65/100, Training Loss: 0.6311, Training Accuracy: 0.7914\n",
      "Epoch 65/100, Validation Loss: 1.0778, Validation Accuracy: 0.6998\n",
      "--------------------------------------------------\n",
      "Epoch 66/100, Training Loss: 0.6600, Training Accuracy: 0.7828\n",
      "Epoch 66/100, Validation Loss: 1.0396, Validation Accuracy: 0.7422\n",
      "--------------------------------------------------\n",
      "Epoch 67/100, Training Loss: 0.6063, Training Accuracy: 0.7966\n",
      "Epoch 67/100, Validation Loss: 1.0032, Validation Accuracy: 0.7400\n",
      "--------------------------------------------------\n",
      "Epoch 68/100, Training Loss: 0.5809, Training Accuracy: 0.8052\n",
      "Epoch 68/100, Validation Loss: 1.0527, Validation Accuracy: 0.7196\n",
      "--------------------------------------------------\n",
      "Epoch 69/100, Training Loss: 0.6366, Training Accuracy: 0.7879\n",
      "Epoch 69/100, Validation Loss: 0.9987, Validation Accuracy: 0.7479\n",
      "--------------------------------------------------\n",
      "Epoch 70/100, Training Loss: 0.5589, Training Accuracy: 0.8172\n",
      "Epoch 70/100, Validation Loss: 1.0505, Validation Accuracy: 0.7326\n",
      "--------------------------------------------------\n",
      "Epoch 71/100, Training Loss: 0.6090, Training Accuracy: 0.7931\n",
      "Epoch 71/100, Validation Loss: 0.9812, Validation Accuracy: 0.7394\n",
      "--------------------------------------------------\n",
      "Epoch 72/100, Training Loss: 0.5622, Training Accuracy: 0.8103\n",
      "Epoch 72/100, Validation Loss: 0.9786, Validation Accuracy: 0.7417\n",
      "--------------------------------------------------\n",
      "Epoch 73/100, Training Loss: 0.5646, Training Accuracy: 0.8086\n",
      "Epoch 73/100, Validation Loss: 0.9694, Validation Accuracy: 0.7490\n",
      "--------------------------------------------------\n",
      "Epoch 74/100, Training Loss: 0.5472, Training Accuracy: 0.8172\n",
      "Epoch 74/100, Validation Loss: 0.9660, Validation Accuracy: 0.7479\n",
      "--------------------------------------------------\n",
      "Epoch 75/100, Training Loss: 0.5269, Training Accuracy: 0.8103\n",
      "Epoch 75/100, Validation Loss: 1.0100, Validation Accuracy: 0.7275\n",
      "--------------------------------------------------\n",
      "Epoch 76/100, Training Loss: 0.5489, Training Accuracy: 0.8241\n",
      "Epoch 76/100, Validation Loss: 0.9583, Validation Accuracy: 0.7541\n",
      "--------------------------------------------------\n",
      "Epoch 77/100, Training Loss: 0.4954, Training Accuracy: 0.8379\n",
      "Epoch 77/100, Validation Loss: 0.9682, Validation Accuracy: 0.7422\n",
      "--------------------------------------------------\n",
      "Epoch 78/100, Training Loss: 0.4999, Training Accuracy: 0.8310\n",
      "Epoch 78/100, Validation Loss: 0.9763, Validation Accuracy: 0.7434\n",
      "--------------------------------------------------\n",
      "Epoch 79/100, Training Loss: 0.4995, Training Accuracy: 0.8328\n",
      "Epoch 79/100, Validation Loss: 0.9523, Validation Accuracy: 0.7535\n",
      "--------------------------------------------------\n",
      "Epoch 80/100, Training Loss: 0.4632, Training Accuracy: 0.8483\n",
      "Epoch 80/100, Validation Loss: 0.9857, Validation Accuracy: 0.7592\n",
      "--------------------------------------------------\n",
      "Epoch 81/100, Training Loss: 0.4793, Training Accuracy: 0.8293\n",
      "Epoch 81/100, Validation Loss: 0.9761, Validation Accuracy: 0.7614\n",
      "--------------------------------------------------\n",
      "Epoch 82/100, Training Loss: 0.4592, Training Accuracy: 0.8431\n",
      "Epoch 82/100, Validation Loss: 0.9699, Validation Accuracy: 0.7637\n",
      "--------------------------------------------------\n",
      "Epoch 83/100, Training Loss: 0.4420, Training Accuracy: 0.8621\n",
      "Epoch 83/100, Validation Loss: 0.9918, Validation Accuracy: 0.7614\n",
      "--------------------------------------------------\n",
      "Epoch 84/100, Training Loss: 0.4495, Training Accuracy: 0.8534\n",
      "Epoch 84/100, Validation Loss: 0.9859, Validation Accuracy: 0.7575\n",
      "--------------------------------------------------\n",
      "Epoch 85/100, Training Loss: 0.4340, Training Accuracy: 0.8500\n",
      "Epoch 85/100, Validation Loss: 0.9988, Validation Accuracy: 0.7631\n",
      "--------------------------------------------------\n",
      "Epoch 86/100, Training Loss: 0.4327, Training Accuracy: 0.8500\n",
      "Epoch 86/100, Validation Loss: 1.0046, Validation Accuracy: 0.7631\n",
      "--------------------------------------------------\n",
      "Epoch 87/100, Training Loss: 0.4341, Training Accuracy: 0.8603\n",
      "Epoch 87/100, Validation Loss: 0.9972, Validation Accuracy: 0.7637\n",
      "--------------------------------------------------\n",
      "Epoch 88/100, Training Loss: 0.4169, Training Accuracy: 0.8569\n",
      "Epoch 88/100, Validation Loss: 0.9952, Validation Accuracy: 0.7671\n",
      "--------------------------------------------------\n",
      "Epoch 89/100, Training Loss: 0.4053, Training Accuracy: 0.8621\n",
      "Epoch 89/100, Validation Loss: 1.0040, Validation Accuracy: 0.7682\n",
      "--------------------------------------------------\n",
      "Epoch 90/100, Training Loss: 0.3940, Training Accuracy: 0.8569\n",
      "Epoch 90/100, Validation Loss: 0.9914, Validation Accuracy: 0.7739\n",
      "--------------------------------------------------\n",
      "Epoch 91/100, Training Loss: 0.3813, Training Accuracy: 0.8690\n",
      "Epoch 91/100, Validation Loss: 1.0057, Validation Accuracy: 0.7654\n",
      "--------------------------------------------------\n",
      "Epoch 92/100, Training Loss: 0.3821, Training Accuracy: 0.8603\n",
      "Epoch 92/100, Validation Loss: 0.9966, Validation Accuracy: 0.7756\n",
      "--------------------------------------------------\n",
      "Epoch 93/100, Training Loss: 0.3761, Training Accuracy: 0.8793\n",
      "Epoch 93/100, Validation Loss: 1.0256, Validation Accuracy: 0.7773\n",
      "--------------------------------------------------\n",
      "Epoch 94/100, Training Loss: 0.3809, Training Accuracy: 0.8724\n",
      "Epoch 94/100, Validation Loss: 1.0385, Validation Accuracy: 0.7722\n",
      "--------------------------------------------------\n",
      "Epoch 95/100, Training Loss: 0.3945, Training Accuracy: 0.8759\n",
      "Epoch 95/100, Validation Loss: 1.0739, Validation Accuracy: 0.7660\n",
      "--------------------------------------------------\n",
      "Epoch 96/100, Training Loss: 0.4052, Training Accuracy: 0.8534\n",
      "Epoch 96/100, Validation Loss: 1.0721, Validation Accuracy: 0.7705\n",
      "--------------------------------------------------\n",
      "Epoch 97/100, Training Loss: 0.4157, Training Accuracy: 0.8638\n",
      "Epoch 97/100, Validation Loss: 1.0455, Validation Accuracy: 0.7733\n",
      "--------------------------------------------------\n",
      "Epoch 98/100, Training Loss: 0.3698, Training Accuracy: 0.8638\n",
      "Epoch 98/100, Validation Loss: 1.0227, Validation Accuracy: 0.7846\n",
      "--------------------------------------------------\n",
      "Epoch 99/100, Training Loss: 0.3448, Training Accuracy: 0.8862\n",
      "Epoch 99/100, Validation Loss: 1.0465, Validation Accuracy: 0.7733\n",
      "--------------------------------------------------\n",
      "Epoch 100/100, Training Loss: 0.3764, Training Accuracy: 0.8759\n",
      "Epoch 100/100, Validation Loss: 1.0530, Validation Accuracy: 0.7592\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training loop for 10 epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Specify the mask indices for train and validation\n",
    "mask_idx_train = 0\n",
    "mask_idx_val = 1\n",
    "train_mask = all_data.train_mask[:, mask_idx_train]\n",
    "val_mask = all_data.val_mask[:, mask_idx_val]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gcn.parameters(), lr=0.003)\n",
    "\n",
    "# Define your validation dataset similar to the training dataset\n",
    "\n",
    "\n",
    "transforms = Graph_to_Subgraph(mode='transformer_5')\n",
    "dataset = wikics.WikiCS(root=root, transform=transforms)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    gcn.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Training phase\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        x, y, edge_index = batch.x, batch.y, batch.edge_index\n",
    "        output = gcn(batch)\n",
    "        output, y = output[batch.ground_node], y\n",
    "        loss = criterion(output[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_acc = calculate_accuracy(output, y, train_mask)\n",
    "\n",
    "    # Print the average loss for the current epoch\n",
    "    average_loss = epoch_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {average_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    gcn.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for batch in loader:\n",
    "            x, y, edge_index = batch.x, batch.y, batch.edge_index\n",
    "            output = gcn(batch)\n",
    "            output, y = output[batch.ground_node], y\n",
    "            val_loss += criterion(output[val_mask], y[val_mask]).item()\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_acc = calculate_accuracy(output, y, val_mask)\n",
    "\n",
    "        average_val_loss = val_loss / len(loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # print a straight line to separate epochs\n",
    "        print(\"--------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}